{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script tests difference of SE between response group and non-response group at SIG1/SIG2 clsuter raised in original study and compute S score for each sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script tests difference of SE between response group and non-response group at SIG1/SIG2 clsuter raised in original study and compute S score for each sample.\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import abd_profile\n",
    "import os\n",
    "import pandas as pd\n",
    "import GCN\n",
    "import copy\n",
    "import numpy as np\n",
    "import tree_util\n",
    "import se\n",
    "from scipy.stats import mannwhitneyu\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from statsmodels.stats.multitest import fdrcorrection as fdr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer = '../data'\n",
    "outdir = '../result/immu/SE_sig'\n",
    "indir= os.path.join(outer, 'immu')\n",
    "#input dir: including metadata.tsv and abd.tsv\n",
    "# output result to dir\n",
    "# load distance, abundance profile and metadata\n",
    "abd_path = os.path.join(indir, 'merged_species.txt')\n",
    "metadata_path = os.path.join(indir, 'metadata.txt')\n",
    "ori_GCN = GCN.input_GCN('../data/gcn2008.tsv', transfer=True)\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "related_abd_df = pd.read_csv('../data/immu/sig.txt', sep='\\t', header=0, index_col=None)\n",
    "raw_profile = abd_profile.input_profile(abd_path, transfer=True)\n",
    "raw_profile = raw_profile[list(set(d_df.index).intersection(set(raw_profile.columns)))]\n",
    "metadata = pd.read_csv(metadata_path, sep=',', header=0)\n",
    "metadata.fillna('NA', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load species list of sig1 and sig2\n",
    "sig_dict = {}\n",
    "sig_dict['sig1'] = list(related_abd_df[related_abd_df['SIG'] == 'SIG1']['MGS'])\n",
    "sig_dict['sig1'] = [x.replace(' ', '_') for x in sig_dict['sig1']]\n",
    "sig_dict['sig1'] = ['s__{}'.format(x) for x in sig_dict['sig1']]\n",
    "sig_dict['sig2'] = list(related_abd_df[related_abd_df['SIG'] == 'SIG2']['MGS'])\n",
    "sig_dict['sig2'] = [x.replace(' ', '_') for x in sig_dict['sig2']]\n",
    "sig_dict['sig2'] = ['s__{}'.format(x) for x in sig_dict['sig2']]\n",
    "sig_dict['sig3'] = list(set(raw_profile.columns).difference(set(sig_dict['sig1'] + sig_dict['sig2'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dict = {'sig1': 'root', 'sig2': 'root', 'sig3': 'root'}\n",
    "for sp in raw_profile.columns:\n",
    "    if sp in sig_dict['sig1']:\n",
    "        parent_dict[sp] = 'sig1'\n",
    "    elif sp in sig_dict['sig2']:\n",
    "        parent_dict[sp] = 'sig2'\n",
    "    else:\n",
    "        parent_dict[sp] = 'sig3'\n",
    "\n",
    "node_leaves = copy.deepcopy(sig_dict)\n",
    "leaf_list = list(raw_profile.columns)\n",
    "subtree_nodes = {}\n",
    "for l in leaf_list:\n",
    "    parent = parent_dict[l]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent].append(l)\n",
    "\n",
    "for node in node_leaves.keys():\n",
    "    parent = parent_dict[node]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent] += subtree_nodes[node]\n",
    "    subtree_nodes[parent].append(node)\n",
    "\n",
    "for node in subtree_nodes.keys():\n",
    "    subtree_nodes[node].append(node)\n",
    "\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)\n",
    "\n",
    "node_leaves['root'] = leaf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR network\n",
    "def fr(d_df, profile, sname):\n",
    "    #print(profile.columns, d_df.index)\n",
    "    sp_list = list(set(profile.columns).intersection(set(d_df.index)))\n",
    "    #print(sp_list)\n",
    "    sp_d_df = d_df.loc[sp_list, sp_list]\n",
    "    #print(profile)\n",
    "    sp_profile = np.array(profile.loc[sname, sp_list])\n",
    "    value = np.dot(sp_profile.reshape(len(sp_profile), 1),sp_profile.reshape(1, len(sp_profile)))\n",
    "    width = value.shape[0]\n",
    "    cor_df = np.ones(shape=(width, width)) - sp_d_df.values\n",
    "    for i in range(width):\n",
    "        cor_df[i][i] = 0\n",
    "    value = np.multiply(value, cor_df)\n",
    "    fr_df = pd.DataFrame(value, index=sp_list, columns=sp_list)\n",
    "    return fr_df\n",
    "\n",
    "# compute SE for all sample\n",
    "def multisample_se(profile, d_df, parent_dict, node_leaves, child_dict, direct_children_dict, param):\n",
    "    result = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys())))\n",
    "    for sname in profile.index:\n",
    "        # print(sname)\n",
    "        edge_df = fr(d_df, profile, sname)\n",
    "        tmp = se.subtree_se_adj(edge_df, parent_dict, node_leaves, child_dict, direct_children_dict, param)\n",
    "        for node in tmp.keys():\n",
    "            value = tmp[node]\n",
    "            result.loc[sname, node] = value\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_list = ['Disc', 'Valid']\n",
    "cohort_se_dict = {}\n",
    "param = 0.5\n",
    "\n",
    "# compute SE for all samples\n",
    "for cohort in cohort_list:\n",
    "    metadata_cohort = metadata[(metadata['Cohort'] == cohort)] #  \n",
    "    metadata_cohort = metadata_cohort[metadata_cohort['Sample Name'].isin(list(raw_profile.index))]\n",
    "\n",
    "\n",
    "    selected_raw_profile = raw_profile.loc[list(metadata_cohort['Sample Name']), :]\n",
    "    crc_profile = abd_profile.check(selected_raw_profile, d_df)\n",
    "\n",
    "    pheno_list = {}\n",
    "    pheno_profiles = {}\n",
    "    for i in metadata_cohort.index:\n",
    "        pheno = metadata_cohort.loc[i, 'OS12']\n",
    "        if pheno == 'NA':\n",
    "            continue\n",
    "        if pheno not in pheno_list.keys():\n",
    "            pheno_list[pheno] = []\n",
    "        if metadata_cohort.loc[i, 'Sample Name'] in list(crc_profile.index):\n",
    "            pheno_list[pheno].append(metadata_cohort.loc[i, 'Sample Name'])\n",
    "\n",
    "    for c, clist in pheno_list.items():\n",
    "        pheno_profiles[c] = copy.deepcopy(crc_profile.loc[clist, :])\n",
    "    \n",
    "    se_result = {}   \n",
    "    for p, profile in pheno_profiles.items():\n",
    "        p_result = multisample_se(profile, d_df, parent_dict, node_leaves, subtree_nodes, direct_children_dict, param)\n",
    "        se_result[p] = p_result\n",
    "\n",
    "    cohort_se_dict[cohort] = copy.deepcopy(se_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output se to files\n",
    "for cohort in cohort_se_dict.keys():\n",
    "    odir = os.path.join(outdir, cohort)\n",
    "    if not os.path.exists(odir):\n",
    "        os.makedirs(odir)\n",
    "    \n",
    "    phenos = list(cohort_se_dict[cohort].keys())\n",
    "    for pheno in phenos:\n",
    "        cohort_se_dict[cohort][pheno].to_csv(os.path.join(odir, 'se_{}.tsv'.format(pheno)), sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "p_cutoff = 0.05\n",
    "\n",
    "# differential test \n",
    "p_df = pd.DataFrame()\n",
    "mean_df = pd.DataFrame()\n",
    "valid_dict = {}\n",
    "show_node = []\n",
    "\n",
    "for cohort in cohort_se_dict.keys():\n",
    "    \n",
    "    if 'NR' not in cohort_se_dict[cohort].keys():\n",
    "        continue\n",
    "    if 'R' not in cohort_se_dict[cohort].keys():\n",
    "        continue\n",
    "    if cohort not in valid_dict.keys():\n",
    "        valid_dict[cohort] = []\n",
    "    l_se1 = cohort_se_dict[cohort]['NR']\n",
    "    l_se2 = cohort_se_dict[cohort]['R']\n",
    "    for inode in l_se1.columns:\n",
    "        if (list(l_se1[inode]).count(0) > len(list(l_se1[inode]))*0.8) and (list(l_se2[inode]).count(0) > len(list(l_se2[inode]))*0.8):\n",
    "            continue\n",
    "        valid_dict[cohort].append(inode)\n",
    "        t, p1 = mannwhitneyu(list(l_se1[inode]), list(l_se2[inode]))\n",
    "        p_df.loc[cohort, inode] = p1\n",
    "        mean_df.loc[cohort, inode] = np.mean(l_se1[inode]) - np.mean(l_se2[inode])\n",
    "p_df.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust p-values by FDR\n",
    "for dir in p_df.index:\n",
    "    valid_nodes = valid_dict[dir]\n",
    "    p_vector = list(p_df.loc[dir, valid_nodes])\n",
    "    p_adj = fdr(p_vector, p_cutoff)[1]\n",
    "    for i, node in enumerate(valid_nodes):\n",
    "        p_df.loc[dir, node] = p_adj[i]\n",
    "p_df.to_csv(os.path.join(outdir, 'p_all_cohorts.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_plot = pd.DataFrame()\n",
    "for dir in p_df.index:\n",
    "    for inode in p_df.columns:\n",
    "        p1 = p_df.loc[dir, inode]\n",
    "        if pd.isna(p1):\n",
    "            node_plot.loc[dir, inode] = np.nan\n",
    "        elif p1 < p_cutoff:\n",
    "            if mean_df.loc[dir, inode] > 0:\n",
    "                node_plot.loc[dir, inode] = 1\n",
    "            else:\n",
    "                node_plot.loc[dir, inode] = -1\n",
    "        else:\n",
    "            node_plot.loc[dir, inode] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n",
    "show_node = []   \n",
    "part_df = node_plot\n",
    "for inode in part_df.columns:\n",
    "    all_zero = True\n",
    "    all_nan = True\n",
    "    for dir in part_df.index:\n",
    "        if not pd.isna(node_plot.loc[dir, inode]):\n",
    "            all_nan = False\n",
    "        if node_plot.loc[dir, inode] != 0:\n",
    "            all_zero = False\n",
    "    if not (all_zero or all_nan):\n",
    "        show_node.append(inode)\n",
    "plt.figure(figsize=(5, 12))\n",
    "part_df = part_df[show_node]\n",
    "non_zero_count = part_df.astype(bool).sum(axis=0) - part_df.isnull().sum(axis=0)\n",
    "sorted_df = part_df.iloc[:, non_zero_count.argsort()]\n",
    "#show_node = sorted(show_node)\n",
    "sns.heatmap(sorted_df.T, vmax=1, vmin=-1, square=True, linecolor='black', cbar=False, xticklabels=True, yticklabels=True, linewidths=1, cmap=\"coolwarm\")\n",
    "plt.title('Different SE of NSCLC cohorts')\n",
    "plt.xticks(rotation=90)\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "opath = os.path.join(outdir, 'NSCLC.pdf')\n",
    "plt.tight_layout()\n",
    "plt.savefig(opath, dpi=300, format='pdf')\n",
    "part_df[show_node].to_csv(os.path.join(outdir, 'NSCLC.tsv'), sep='\\t')\n",
    "#plt.show()\n",
    "#print(part_df[show_node].shape)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "abd_path = os.path.join(indir, 'merged_species.txt')\n",
    "raw_profile = abd_profile.input_profile(abd_path, transfer=True)\n",
    "raw_profile = raw_profile[list(set(d_df.index).intersection(set(raw_profile.columns)))]\n",
    "metadata_path = os.path.join(indir, 'metadata.txt')\n",
    "metadata = pd.read_csv(metadata_path, sep=',', header=0)\n",
    "metadata.fillna('NA', inplace=True)\n",
    "metadata_cohort = metadata[(metadata['Cohort'] == 'Disc')] #  \n",
    "metadata_cohort = metadata_cohort[metadata_cohort['Sample Name'].isin(list(raw_profile.index))]\n",
    "selected_raw_profile = raw_profile.loc[list(metadata_cohort['Sample Name']), :]\n",
    "disc_profile = abd_profile.check(selected_raw_profile, d_df)\n",
    "delete_sp = []\n",
    "binary_disc = copy.deepcopy(disc_profile)\n",
    "binary_disc[binary_disc > 0] = 1\n",
    "for sp in disc_profile.columns:\n",
    "    if binary_disc[sp].sum() < len(disc_profile)*2.5/100:\n",
    "        delete_sp.append(sp)\n",
    "disc_profile.drop(columns=delete_sp, inplace=True)\n",
    "clusters = ['sig1', 'sig2']\n",
    "interested_dict = {}\n",
    "num_dict = {}\n",
    "cluster_sp_dict = {}\n",
    "for cluster in clusters:\n",
    "    leaves = node_leaves[cluster]\n",
    "    leaves = [leaf.replace('-', '_') for leaf in leaves]\n",
    "    common_sp = list(set(disc_profile.columns).intersection(set(leaves)))\n",
    "    interested_dict[cluster] = copy.deepcopy(disc_profile[common_sp])\n",
    "    num_dict[cluster] = len(common_sp)\n",
    "    cluster_sp_dict[cluster] = ','.join(common_sp)\n",
    "\n",
    "with open(os.path.join(outdir, 'cluster.tsv'), 'w') as fp:\n",
    "    s = 'cluster\\tsize\\tleaves\\n'\n",
    "    for cluster in clusters:\n",
    "        s += '{}\\t{}\\t{}\\n'.format(cluster, num_dict[cluster], ','.join(list(interested_dict[cluster].columns)))\n",
    "    fp.write(s)\n",
    "\n",
    "json.dump(cluster_sp_dict, open(os.path.join(outdir, 'cluster_sp.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR S Score\n",
    "existed_sp = {}\n",
    "cluster_ratio = {}\n",
    "for cluster in clusters:\n",
    "    cluster_p = interested_dict[cluster]\n",
    "    column_medians = cluster_p.median()\n",
    "    for sp in cluster_p.columns:\n",
    "        cluster_p.loc[:, sp] = cluster_p.loc[:, sp] - column_medians[sp]\n",
    "    cluster_p[cluster_p > 0] = 1\n",
    "    cluster_p[cluster_p < 0] = 0\n",
    "    total_n = num_dict[cluster]\n",
    "    # sum by row\n",
    "    sum_result = cluster_p.sum(axis=1)\n",
    "    ratio = sum_result/total_n\n",
    "    cluster_ratio[cluster] = copy.deepcopy(ratio)\n",
    "    existed_sp[cluster] = {}\n",
    "    for sample in cluster_p.index:\n",
    "        existed_sp[cluster][sample] = []\n",
    "        for sp in cluster_p.columns:\n",
    "            if cluster_p.loc[sample, sp] == 1:\n",
    "                existed_sp[cluster][sample].append(sp)\n",
    "        existed_sp[cluster][sample] = ','.join(existed_sp[cluster][sample])\n",
    "json.dump(existed_sp, open(os.path.join(outdir, 'existed_sp.json'), 'w'))\n",
    "result_score = (cluster_ratio[clusters[1]]-cluster_ratio[clusters[0]][cluster_ratio[clusters[0]].index]+1)/2\n",
    "result_score.to_csv(os.path.join(outdir, 'score_disc.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142857142857\n",
      "0.7301587301587301\n",
      "0.4076923076923077\n",
      "0.65\n",
      "130\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# merge FR S score to metadata and binary classification TOPOB01\n",
    "DS1 = pd.read_csv('../data/immu/DS1_oncology_clinical_data.csv', header=0)\n",
    "DS1 = DS1[DS1['Cohort']=='Disc']\n",
    "DS1.set_index('Sample_id', inplace=True)\n",
    "DS1.dropna(subset=['OS12'], inplace=True)\n",
    "DS1['Sample_id'] = DS1.index\n",
    "\n",
    "pred_disc = pd.read_csv(os.path.join(outdir, 'score_disc.tsv'), sep='\\t', header=0, index_col=0)\n",
    "DS1['TOPOB01'] = pred_disc.loc[DS1.index, '0']\n",
    "DS1.sort_values(by='TOPOB01').to_csv(os.path.join(outdir, 'pred_disc.tsv'), sep='\\t', index=False)\n",
    "\n",
    "DS1.loc[DS1[DS1['TOPOB01'] < 0.499].index, 'TOPOB01'] = 0\n",
    "DS1.loc[DS1[DS1['TOPOB01'] >= 0.722].index, 'TOPOB01'] = 1\n",
    "pred_DS1 = DS1[(DS1['TOPOB01'] == 0) | (DS1['TOPOB01'] == 1)]\n",
    "pred_DS1.to_csv(os.path.join(outdir, 'pred_binary_disc.tsv'), sep='\\t', index=False)\n",
    "print(len(pred_DS1[((pred_DS1['OS12']=='R')&(pred_DS1['TOPOB01'] == 0))])/len(pred_DS1[pred_DS1['TOPOB01'] == 0]))\n",
    "print(len(pred_DS1[((pred_DS1['OS12']=='R')&(pred_DS1['TOPOB01'] == 1))])/len(pred_DS1[pred_DS1['TOPOB01'] == 1]))\n",
    "\n",
    "# NR [56] < 0.50 < gray_zone [111] < 0.72 < R [63]\n",
    "# auc = 0.7218449\n",
    "\n",
    "# add akk\n",
    "for sample in DS1.index:\n",
    "    if DS1.loc[sample, 'TOPOB01'] < 1 and DS1.loc[sample, 'TOPOB01'] > 0:\n",
    "        if DS1.loc[sample, 'AKK_TRICHO'] == 'Low':\n",
    "            DS1.loc[sample, 'TOPOB01'] = 1\n",
    "        else:\n",
    "            DS1.loc[sample, 'TOPOB01'] = 0\n",
    "DS1.to_csv(os.path.join(outdir, 'pred_disc_akk.tsv'), sep='\\t', index=False)\n",
    "# auc = 0.62\n",
    "print(len(DS1[((DS1['OS12']=='R')&(DS1['TOPOB01'] == 0))])/len(DS1[DS1['TOPOB01'] == 0]))\n",
    "print(len(DS1[((DS1['OS12']=='R')&(DS1['TOPOB01'] == 1))])/len(DS1[DS1['TOPOB01'] == 1]))\n",
    "print(len(DS1[DS1['TOPOB01'] == 0]))\n",
    "print(len(DS1[DS1['TOPOB01'] == 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
