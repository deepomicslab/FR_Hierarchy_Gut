{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot keystone figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "#id pheno\n",
    "indir = \"../result/large_scale_cohort\"\n",
    "leave_path = \"../result/GCN_fix_tree/leaves_cluster.tsv\"\n",
    "outdir = \"../result/keystone\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "plist = ['ACVD',\n",
    " 'BD',\n",
    " 'CRC',\n",
    " 'IBD',\n",
    " 'IGT',\n",
    " 'CFS',\n",
    " 'STH',\n",
    " 'T2D',\n",
    " 'adenoma',\n",
    " 'asthma',\n",
    " 'carcinoma_surgery_history',\n",
    " 'hypertension',\n",
    " 'migraine',\n",
    " 'schizofrenia']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "indir = \"../result/large_scale_cohort\"\n",
    "leave_path = \"../result/GCN_fix_tree/leaves_cluster.tsv\"\n",
    "outdir = \"../result/keystone\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "plist = ['ACVD', 'BD', 'CRC', 'IBD', 'IGT', 'CFS', 'STH', 'T2D', 'adenoma', \n",
    "         'asthma', 'carcinoma_surgery_history', 'hypertension', 'migraine', 'schizofrenia']\n",
    "\n",
    "def process_keystone_analysis(cohort_id, disease, indir, leave_path, outdir):\n",
    "    \"\"\"\n",
    "    Process keystone analysis for a given cohort and disease\n",
    "    \"\"\"\n",
    "    # File paths\n",
    "    sp_dir = f\"{indir}/{disease}/{cohort_id}/sp\"\n",
    "    diff_file = f\"{indir}/{disease}/{cohort_id}/{cohort_id}.abundance.wilcox_testing.tsv\"\n",
    "    \n",
    "    groups = ['Health', disease]\n",
    "    n = 30\n",
    "    \n",
    "    # Output files\n",
    "    keystone_file = f\"{outdir}/{cohort_id}.keystone.species.list\"\n",
    "    group_pr_file = f\"{outdir}/{cohort_id}.group_PR.tsv\"\n",
    "    diff_out_file = f\"{outdir}/{cohort_id}.diff.tsv\"\n",
    "    \n",
    "    print(f\"Processing {cohort_id}\")\n",
    "    \n",
    "    # Read name mapping\n",
    "    newtax = {}\n",
    "    try:\n",
    "        with open(\"species.name_short.txt\", 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    tax, new_tax = parts[0], parts[1]\n",
    "                    newtax[f\"s__{tax}\"] = new_tax\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning:species.name_short.txt file not found\")\n",
    "    \n",
    "    # Process each group\n",
    "    species_info = {}\n",
    "    pr_info = {}\n",
    "    total_pr = {}\n",
    "    eigen_c_dict = {}\n",
    "    \n",
    "    for g in groups:\n",
    "        keystone_file_path = f\"{sp_dir}/cluster_{g}/keystone_node.tsv\"\n",
    "        \n",
    "        if not os.path.exists(keystone_file_path):\n",
    "            print(f\"Warning: {keystone_file_path} not found\")\n",
    "            continue\n",
    "            \n",
    "        # Find eigen_c\n",
    "        eigen_c = None\n",
    "        with open(keystone_file_path, 'r') as f:\n",
    "            header = f.readline()  # Skip header\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 6:\n",
    "                    spe, l, pr, eigen, c, p = parts\n",
    "                    if eigen == 'True' and l == '0':\n",
    "                        eigen_c = p\n",
    "                        break\n",
    "        \n",
    "        eigen_c_dict[g] = eigen_c\n",
    "        \n",
    "        # Process species\n",
    "        with open(keystone_file_path, 'r') as f:\n",
    "            header = f.readline()  # Skip header\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 6:\n",
    "                    spe, l, pr, eigen, c, p = parts\n",
    "                    \n",
    "                    # Skip if we can't convert pr to float (likely header or malformed data)\n",
    "                    try:\n",
    "                        pr_value = float(pr)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    \n",
    "                    if p == eigen_c and l == '0':\n",
    "                        if spe not in species_info:\n",
    "                            species_info[spe] = {}\n",
    "                        \n",
    "                        if eigen == 'True':\n",
    "                            species_info[spe][g] = 2\n",
    "                            print(f\"{spe}\\t{g}\")\n",
    "                        else:\n",
    "                            species_info[spe][g] = 1\n",
    "                    \n",
    "                    if spe not in pr_info:\n",
    "                        pr_info[spe] = {}\n",
    "                    pr_info[spe][g] = pr_value\n",
    "                    \n",
    "                    if spe.startswith('s__'):\n",
    "                        if spe not in total_pr:\n",
    "                            total_pr[spe] = 0\n",
    "                        total_pr[spe] += pr_value\n",
    "    \n",
    "    # Write keystone species list\n",
    "    with open(keystone_file, 'w') as f:\n",
    "        for g in groups:\n",
    "            keystone_file_path = f\"{sp_dir}/cluster_{g}/keystone_node.tsv\"\n",
    "            if os.path.exists(keystone_file_path):\n",
    "                with open(keystone_file_path, 'r') as kf:\n",
    "                    header = kf.readline()  # Skip header\n",
    "                    for line in kf:\n",
    "                        parts = line.strip().split('\\t')\n",
    "                        if len(parts) >= 6:\n",
    "                            spe, l, pr, eigen, c, p = parts\n",
    "                            if eigen == 'True' and l == '0':\n",
    "                                mapped_name = newtax.get(spe, spe)\n",
    "                                f.write(f\"{mapped_name}\\n\")\n",
    "    \n",
    "    # Fill missing values\n",
    "    for g in groups:\n",
    "        for spe in species_info:\n",
    "            if g not in species_info[spe]:\n",
    "                species_info[spe][g] = 0\n",
    "    \n",
    "    # Get top species by PageRank\n",
    "    rank_in = {}\n",
    "    count = 0\n",
    "    for spe in sorted(total_pr.keys(), key=lambda x: total_pr[x], reverse=True):\n",
    "        count += 1\n",
    "        if count > n * 2:\n",
    "            break\n",
    "        rank_in[spe] = 1\n",
    "    \n",
    "    # Process differential abundance results\n",
    "    if not os.path.exists(diff_file):\n",
    "        print(f\"Warning: {diff_file} not found\")\n",
    "        return\n",
    "    \n",
    "    diff_df = pd.read_csv(diff_file, sep='\\t')\n",
    "    \n",
    "    # Write group PR results\n",
    "    with open(group_pr_file, 'w') as f:\n",
    "        f.write(\"Taxa\\tPR_control\\tPR_case\\teigen_control\\teigen_case\\n\")\n",
    "        \n",
    "        for _, row in diff_df.iterrows():\n",
    "            tax = row.iloc[0]  # First column is taxa\n",
    "            \n",
    "            if tax not in rank_in and tax not in species_info:\n",
    "                continue\n",
    "            \n",
    "            fdr = row.iloc[-1]  # Last column is FDR\n",
    "            case, control = row.iloc[2], row.iloc[3]  # Assuming these are case/control columns\n",
    "            \n",
    "            if tax in species_info:\n",
    "                eigen_control = species_info[tax].get(groups[0], 0)\n",
    "                eigen_case = species_info[tax].get(groups[1], 0)\n",
    "            else:\n",
    "                eigen_control, eigen_case = 0, 0\n",
    "            \n",
    "            pr_control = pr_info.get(tax, {}).get(groups[0], 0)\n",
    "            pr_case = pr_info.get(tax, {}).get(groups[1], 0)\n",
    "            \n",
    "            mapped_name = newtax.get(tax, tax)\n",
    "            f.write(f\"{mapped_name}\\t{pr_control:.4f}\\t{pr_case:.4f}\\t{eigen_control}\\t{eigen_case}\\n\")\n",
    "    \n",
    "    # Read phylum colors\n",
    "    in_phy = {}\n",
    "    try:\n",
    "        with open(\"phylum.color\", 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    phy, color = parts[0], parts[1]\n",
    "                    in_phy[phy] = 1\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: phylum.color file not found\")\n",
    "    \n",
    "    # Write diff results\n",
    "    with open(diff_out_file, 'w') as f:\n",
    "        f.write(\"Taxa\\tFeature\\tRes\\n\")\n",
    "        \n",
    "        # Process phylum information\n",
    "        try:\n",
    "            with open(\"../data/cMD.select_2008.species_phylum.tsv\", 'r') as pf:\n",
    "                for line in pf:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) >= 2:\n",
    "                        tax, phy = parts[0], parts[1]\n",
    "                        \n",
    "                        if tax not in rank_in and tax not in species_info:\n",
    "                            continue\n",
    "                        \n",
    "                        mapped_name = newtax.get(tax, tax)\n",
    "                        if phy in in_phy:\n",
    "                            out_phy = phy.replace('p__', '')\n",
    "                            f.write(f\"{mapped_name}\\tPhylum\\t{out_phy}\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"{mapped_name}\\tPhylum\\tOther\\n\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Warning: species_phylum file not found\")\n",
    "        \n",
    "        # Process cluster information\n",
    "        try:\n",
    "            cluster_df = pd.read_csv(leave_path, sep='\\t')\n",
    "            for _, row in cluster_df.iterrows():\n",
    "                tax = str(row.iloc[0]).replace('-', '_')\n",
    "                clu = row.iloc[1] if pd.notna(row.iloc[1]) else 'Other'\n",
    "                \n",
    "                if tax not in rank_in and tax not in species_info:\n",
    "                    continue\n",
    "                \n",
    "                mapped_name = newtax.get(tax, tax)\n",
    "                f.write(f\"{mapped_name}\\tCluster\\t{clu}\\n\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {leave_path} not found\")\n",
    "\n",
    "# Main processing loop\n",
    "for disease in plist:\n",
    "    dir_path = os.path.join(indir, disease)\n",
    "    if not os.path.exists(dir_path):\n",
    "        continue\n",
    "        \n",
    "    for cohort_id in os.listdir(dir_path):\n",
    "        cohort_dir = os.path.join(dir_path, cohort_id)\n",
    "        if not os.path.isdir(cohort_dir):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            process_keystone_analysis(cohort_id, disease, indir, leave_path, outdir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {cohort_id} in {disease}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(\"Keystone analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Rscript exists\n",
    "python_executable = sys.executable\n",
    "python_dir = os.path.dirname(python_executable)\n",
    "rscript_path = os.path.join(python_dir, 'Rscript')\n",
    "if os.path.exists(rscript_path):\n",
    "    print(f\"Rscript path: {rscript_path}\")\n",
    "else:\n",
    "    print(f\"Could not find Rscript in Python directory: {rscript_path}\")\n",
    "    print(\"Please ensure R is installed in your conda environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease in plist:\n",
    "    dir_path = os.path.join(indir, disease)\n",
    "    for id in os.listdir(dir_path):\n",
    "        cohort_dir = os.path.join(dir_path, id)\n",
    "        if not os.path.isdir(cohort_dir):\n",
    "            continue\n",
    "        prefix = \"{}/{}\".format(outdir, id)\n",
    "        e = os.system(\"Rscript page_rank.R {} {}\".format(prefix, id))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
