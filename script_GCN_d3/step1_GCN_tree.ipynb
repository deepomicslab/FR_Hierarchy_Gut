{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the pipeline of phenotype analysis\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import pandas as pd\n",
    "import GCN\n",
    "import copy\n",
    "import numpy as np\n",
    "import tree_util\n",
    "from pyseat.SEAT import SEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "outer = '../result/GCN_fix_tree'\n",
    "if not os.path.exists(outer):\n",
    "    os.makedirs(outer)\n",
    "ori_GCN = GCN.input_GCN('../data/gcn2008.tsv', transfer=True)\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "fr_df = pd.DataFrame(1 - d_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat = tree_util.make_tree(fr_df)\n",
    "newick_tree = seat.newick\n",
    "subroot_nodes = seat.se_tree.optimal_subpopulation_node_ids\n",
    "json_tree = tree_util.parse(newick_tree)\n",
    "\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "parent_dict_int = {}\n",
    "for key, value in parent_dict.items():\n",
    "    if value == '':\n",
    "        continue\n",
    "    key_new = int(key[1:])\n",
    "    parent_dict_int[key_new] = int(value[1:])\n",
    "\n",
    "conpact_children_dict = {'root': subroot_nodes}\n",
    "for lid in seat.leaves_list:\n",
    "    conpact_children_dict[lid] = []\n",
    "    first_pid = parent_dict_int[lid]\n",
    "    if first_pid not in conpact_children_dict.keys():\n",
    "        conpact_children_dict[first_pid] = []\n",
    "    conpact_children_dict[first_pid].append(lid)\n",
    "    if first_pid in subroot_nodes:\n",
    "        continue\n",
    "    # find subpopulation\n",
    "    current_aid = first_pid\n",
    "    while current_aid not in subroot_nodes:\n",
    "        current_aid = parent_dict_int[current_aid]\n",
    "    if current_aid not in conpact_children_dict.keys():\n",
    "        conpact_children_dict[current_aid] = []\n",
    "    if first_pid not in conpact_children_dict[current_aid]:\n",
    "        conpact_children_dict[current_aid].append(first_pid)\n",
    "\n",
    "compact_json = tree_util.call_tree(conpact_children_dict, 'root')\n",
    "\n",
    "# rename leaves as species name\n",
    "name_dict, reverse_dict = tree_util.name_reflection(d_df)\n",
    "tree_util.rename_node(compact_json, reverse_dict)\n",
    "newick_tree = tree_util.call_newick(compact_json)\n",
    "newick_tree = newick_tree.replace('_', '-')\n",
    "\n",
    "with open(os.path.join(outer, 'GCN_tree.newick'), 'w') as fp:\n",
    "    fp.write(newick_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tree = tree_util.parse(newick_tree)\n",
    "largest = {'largest': 0}\n",
    "leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "largest_level = largest['largest']\n",
    "nlayer = largest_level\n",
    "layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "node_leaves = {}\n",
    "for level in layer_leaves_dict.keys():\n",
    "    for node, sp_list in layer_leaves_dict[level].items():\n",
    "        if node in node_leaves.keys():\n",
    "            continue\n",
    "        node_leaves[node] = copy.deepcopy(sp_list)\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)\n",
    "\n",
    "leaves_num = pd.DataFrame(columns=['num'], index=list(node_leaves.keys()))\n",
    "for k, v in node_leaves.items():\n",
    "    leaves_num.loc[k, 'num'] = len(v)\n",
    "\n",
    "leaves_num = leaves_num.sort_values(by='num', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tmp_short = 'cluster_C{}'\n",
    "c_tmp = 'cluster_S{}-C{}'\n",
    "sc_tmp = 'supercluster_S{}'\n",
    "# sort and rename supercluster and cluster\n",
    "rename_df = pd.DataFrame(columns=['class', 'leaves n', 'parent_name', 'alias', 'parent_alias']) # name is the index\n",
    "rename_df.loc['nroot', ] = ['root', len(reverse_dict.keys()), 'NA', 'root', 'NA']\n",
    "internal_rename_dict = {'nroot': 'root'}\n",
    "supclusters = []\n",
    "leaf_set = set(leaf_list)\n",
    "\n",
    "children = direct_children_dict['nroot']\n",
    "selected_num = leaves_num.loc[children, ]\n",
    "selected_num = selected_num.sort_values(by='num', ascending=False)\n",
    "i = 0\n",
    "for c in selected_num.index:\n",
    "    i += 1\n",
    "    cchildren = direct_children_dict[c]\n",
    "    if not set(cchildren).issubset(leaf_set):\n",
    "        # is a supercluster\n",
    "        parent = parent_dict[c]\n",
    "        supclusters.append(c)\n",
    "        internal_rename_dict[c] = sc_tmp.format(i)\n",
    "        rename_df.loc[c, ] = ['supercluster', leaves_num.loc[c, 'num'], parent, internal_rename_dict[c], internal_rename_dict[parent]]\n",
    "    else:\n",
    "        parent = parent_dict[c]\n",
    "        internal_rename_dict[c] = c_tmp_short.format(i)\n",
    "        rename_df.loc[c, ] = ['cluster', leaves_num.loc[c, 'num'], parent, internal_rename_dict[c], internal_rename_dict[parent]]\n",
    "\n",
    "\n",
    "for node in supclusters:\n",
    "    children = direct_children_dict[node]\n",
    "    selected_num = leaves_num.loc[children, ]\n",
    "    selected_num = selected_num.sort_values(by='num', ascending=False)\n",
    "    i = 0\n",
    "    for c in selected_num.index:\n",
    "        if not c.startswith('n'):\n",
    "            continue\n",
    "        i += 1\n",
    "        \n",
    "        parent = parent_dict[c]\n",
    "        parent_alias = internal_rename_dict[parent]\n",
    "        digit = parent_alias[14:]\n",
    "        internal_rename_dict[c] = c_tmp.format(digit, i)\n",
    "        if c == 'n3486':\n",
    "            print(parent, internal_rename_dict[c])\n",
    "        rename_df.loc[c, ] = ['cluster', leaves_num.loc[c, 'num'], parent, internal_rename_dict[c], parent_alias]\n",
    "\n",
    "rename_df = rename_df.sort_values(by = 'leaves n', ascending=False)\n",
    "rename_df.to_csv(os.path.join(outer, 'node_rename.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort rule\n",
    "def sort_rule(x):\n",
    "    x = x['name']\n",
    "    if ( 's--' in x) or ('s__' in x):\n",
    "        return x\n",
    "\n",
    "    if 'C' in x:\n",
    "        numx = int(x.split('C')[-1])\n",
    "    else:\n",
    "        numx = int(x.split('S')[-1])\n",
    "    return numx\n",
    "\n",
    "def sort_children(node, sort_rule):\n",
    "    if len(node['children']) > 0:\n",
    "        node['children'] = sorted(node['children'], key=sort_rule)\n",
    "        for c in node['children']:\n",
    "            sort_children(c, sort_rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the cluster and supercluster\n",
    "renamed_json_tree = copy.deepcopy(json_tree)\n",
    "tree_util.rename_node(renamed_json_tree, internal_rename_dict)\n",
    "tree_util.sort_children(renamed_json_tree, sort_rule)\n",
    "newick = tree_util.call_newick(renamed_json_tree)\n",
    "with open(os.path.join(outer, 'renamed_GCN_tree.newick'), 'w') as fp:\n",
    "    fp.write(newick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_newick = tree_util.call_internal_tree(renamed_json_tree, set(leaf_list))\n",
    "with open(os.path.join(outer, 'internal_tree.newick'), 'w') as fp:\n",
    "    fp.write(internal_newick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['cluster', 'super-cluster'], index=leaf_list)\n",
    "df.fillna('NA', inplace=True)\n",
    "for k, leaves in node_leaves.items():\n",
    "    k = rename_df.loc[k, 'alias']\n",
    "    cluster_id = k.split('_')[-1] \n",
    "    contents = cluster_id.split('-')\n",
    "    for l in leaves:\n",
    "        if contents[-1][0] == 'C':\n",
    "            df.loc[l, 'cluster'] = cluster_id\n",
    "        if contents[-1][0] == 'S':\n",
    "            df.loc[l, 'super-cluster'] = contents[-1]\n",
    "        if contents[0][0] == 'S':\n",
    "            if (df.loc[l, 'super-cluster'] != 'NA') and (df.loc[l, 'super-cluster'] !=contents[0]):\n",
    "                print(l, df.loc[l, 'super-cluster'])\n",
    "            df.loc[l, 'super-cluster'] = contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['super-cluster', 'cluster']).to_csv(os.path.join(outer, 'leaves_cluster.tsv'), sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
