{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is to compute FR at each cluster/super-cluster for each timepoint\n",
    "\n",
    "FMT dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is to compute FR at each cluster/supercluster for each timepoint\n",
    "# FMT dataset 1\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import tree_util\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR for a sample\n",
    "def fr_value(d_df, profile, sname):\n",
    "    sp_list = list(profile.columns)\n",
    "    n = len(sp_list)\n",
    "    corr = np.ones(shape=(n, n)) - d_df.loc[sp_list, sp_list].values\n",
    "    np.fill_diagonal(corr, 0)\n",
    "    # print(corr[1, 1])\n",
    "    a = np.array(profile.loc[sname, sp_list])\n",
    "    inter_matrix = np.dot(a.reshape(len(a), 1),a.reshape(1, len(a)))\n",
    "    np.fill_diagonal(inter_matrix, 0)\n",
    "    td = np.sum(inter_matrix)/2\n",
    "    fr = np.sum(np.multiply(inter_matrix, corr))/2\n",
    "    fd = np.sum(np.multiply(inter_matrix, d_df.loc[sp_list, sp_list].values))/2\n",
    "    if td == 0:\n",
    "        return 0\n",
    "    #return fr/td\n",
    "    return fr\n",
    "\n",
    "# compute FR for all sample\n",
    "def multisample_nfr(profile, d_df, node_leaves):\n",
    "    result = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    for sname in profile.index:\n",
    "       for node, sp_list in node_leaves.items():\n",
    "           sp_list = list(set(sp_list).intersection(set(profile.columns)))\n",
    "           selected_d = d_df.loc[sp_list, sp_list]\n",
    "           selected_profile = profile.loc[:, sp_list]\n",
    "           value = fr_value(selected_d, selected_profile, sname)\n",
    "           result.loc[sname, node] = value\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tree\n",
    "outdir = '../result/FMT/FR_timepoints/FMT1'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "with open('../result/GCN_fix_tree/renamed_GCN_tree.newick') as fp:\n",
    "    newick_tree = fp.read()\n",
    "    # newick_tree = newick_tree.replace('-', '_')\n",
    "\n",
    "# construct tree with newick string\n",
    "json_tree = tree_util.parse(newick_tree)\n",
    "largest = {'largest': 0}\n",
    "leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "largest_level = largest['largest']\n",
    "nlayer = largest_level\n",
    "layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "leaves_dict = copy.deepcopy(layer_leaves_dict)\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "node_leaves = {}\n",
    "for level in layer_leaves_dict.keys():\n",
    "    for node, sp_list in layer_leaves_dict[level].items():\n",
    "        if node in node_leaves.keys():\n",
    "            continue\n",
    "        node_leaves[node] = copy.deepcopy(sp_list)\n",
    "subtree_nodes = {}\n",
    "for l in leaf_list:\n",
    "    parent = parent_dict[l]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent].append(l)\n",
    "\n",
    "for node in node_leaves.keys():\n",
    "    parent = parent_dict[node]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent] += subtree_nodes[node]\n",
    "    subtree_nodes[parent].append(node)\n",
    "\n",
    "for node in subtree_nodes.keys():\n",
    "    subtree_nodes[node].append(node)\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)\n",
    "\n",
    "node_leaves['root'] = copy.deepcopy(leaf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance, abundance profile and metadata\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "metadata = pd.read_csv('../data/FMT/FMT1/metadata.tsv', sep='\\t', index_col=None, header=0)\n",
    "abd = pd.read_csv('../data/FMT/FMT1/fmt_abd.tsv', sep='\\t', header=0, index_col=0)\n",
    "name_dict = {}\n",
    "for sp in d_df.columns:\n",
    "        name_dict[sp] = sp.replace('_', '-')\n",
    "d_df = d_df.rename(columns=name_dict, index=name_dict)\n",
    "abd = abd.rename(columns=name_dict)\n",
    "sub_ids = ['FAT_006', 'FAT_015', 'FAT_008', 'FAT_020', 'FAT_012']\n",
    "days = [0, 2, 14, 42, 84]\n",
    "frac_df = pd.read_csv('../data/FMT/FMT1/Li.txt', sep='\\t', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR for all samples at all timepoints\n",
    "profile = abd[list(set(abd.columns).intersection(set(d_df.columns)))]/100\n",
    "rename_dict = {}\n",
    "ids = []\n",
    "i = 1\n",
    "for id in sub_ids:\n",
    "    for d in days:\n",
    "        sid = \"{}-22-{}-0\".format(id, d)\n",
    "        ids.append(sid)\n",
    "        rename_dict[sid] = 'FMT{}_day{}'.format(i,d)\n",
    "    i += 1\n",
    "profile = profile.loc[ids, ].rename(index=rename_dict)\n",
    "# profile.to_csv(os.path.join(outdir, 'abd.tsv'), sep='\\t')\n",
    "fr_df = multisample_nfr(profile, d_df, node_leaves)\n",
    "fr_df = fr_df.T\n",
    "fr_df.drop('nroot', axis=0, inplace=True)\n",
    "fr_df.to_csv(os.path.join(outdir, 'fr.tsv'), sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr_r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
