{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is to compute FR at each cluster/supercluster for each timepoint\n",
    "\n",
    "FMT dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is to compute FR at each cluster/supercluster for each timepoint\n",
    "# FMT dataset 2\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import tree_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR for a sample\n",
    "def fr_value(d_df, profile, sname):\n",
    "    sp_list = list(profile.columns)\n",
    "    n = len(sp_list)\n",
    "    corr = np.ones(shape=(n, n)) - d_df.loc[sp_list, sp_list].values\n",
    "    np.fill_diagonal(corr, 0)\n",
    "    # print(corr[1, 1])\n",
    "    a = np.array(profile.loc[sname, sp_list])\n",
    "    inter_matrix = np.dot(a.reshape(len(a), 1),a.reshape(1, len(a)))\n",
    "    np.fill_diagonal(inter_matrix, 0)\n",
    "    td = np.sum(inter_matrix)/2\n",
    "    fr = np.sum(np.multiply(inter_matrix, corr))/2\n",
    "    fd = np.sum(np.multiply(inter_matrix, d_df.loc[sp_list, sp_list].values))/2\n",
    "    if td == 0:\n",
    "        return 0\n",
    "    #return fr/td\n",
    "    return fr\n",
    "\n",
    "# compute FR for all sample\n",
    "def multisample_fr(profile, d_df, node_leaves):\n",
    "    result = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    for sname in profile.index:\n",
    "       for node, sp_list in node_leaves.items():\n",
    "           sp_list = list(set(sp_list).intersection(set(profile.columns)))\n",
    "           selected_d = d_df.loc[sp_list, sp_list]\n",
    "           selected_profile = profile.loc[:, sp_list]\n",
    "           value = fr_value(selected_d, selected_profile, sname)\n",
    "           result.loc[sname, node] = value\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tree\n",
    "with open('../result/GCN_fix_tree/renamed_GCN_tree.newick') as fp:\n",
    "    newick_tree = fp.read()\n",
    "    # newick_tree = newick_tree.replace('-', '_')\n",
    "\n",
    "# construct tree with newick string\n",
    "json_tree = tree_util.parse(newick_tree)\n",
    "largest = {'largest': 0}\n",
    "leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "largest_level = largest['largest']\n",
    "nlayer = largest_level\n",
    "layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "\n",
    "tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "leaves_dict = copy.deepcopy(layer_leaves_dict)\n",
    "\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "node_leaves = {}\n",
    "for level in layer_leaves_dict.keys():\n",
    "    for node, sp_list in layer_leaves_dict[level].items():\n",
    "        if node in node_leaves.keys():\n",
    "            continue\n",
    "        node_leaves[node] = copy.deepcopy(sp_list)\n",
    "subtree_nodes = {}\n",
    "for l in leaf_list:\n",
    "    parent = parent_dict[l]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent].append(l)\n",
    "\n",
    "for node in node_leaves.keys():\n",
    "    parent = parent_dict[node]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent] += subtree_nodes[node]\n",
    "    subtree_nodes[parent].append(node)\n",
    "\n",
    "for node in subtree_nodes.keys():\n",
    "    subtree_nodes[node].append(node)\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)\n",
    "\n",
    "node_leaves['root'] = copy.deepcopy(leaf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frac_df = pd.read_csv('../data/FMT/FMT2/Eric.txt', sep='\\t', header=0, index_col=0)\n",
    "deltat = pd.read_csv('../data/FMT/FMT2/deltat.txt', sep='\\t', header=0, index_col=0)\n",
    "triads = pd.read_csv('../data/FMT/FMT2/triads.txt', sep='\\t', header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in triads.index:\n",
    "    posts = triads.loc[idx, 'post_samples'].strip().split(',')\n",
    "    times = []\n",
    "    for p in posts:\n",
    "        if p not in deltat.index:\n",
    "            print(p)\n",
    "        else:\n",
    "            times.append(str(deltat.loc[p, 'delta_t']))\n",
    "    t_str = ','.join(times)\n",
    "    triads.loc[idx, 'days'] = t_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in frac_df.index:\n",
    "    d = frac_df.loc[idx, 'Days postFMT']\n",
    "    cand = triads[triads['days'] == d]['pre_sample']\n",
    "    ids = triads[triads['days'] == d].index\n",
    "    if len(cand) == 1:\n",
    "        #print(list(cand))\n",
    "        s = list(cand)[0]\n",
    "        frac_df.loc[idx, 'sname'] = s\n",
    "        triads.loc[list(ids)[0], 'alias'] = idx\n",
    "triads.loc[10, 'alias'] = 'FMT5' \n",
    "s = triads.loc[10, 'pre_sample']\n",
    "frac_df.loc['FMT5', 'sname'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance, abundance profile and metadata\n",
    "outdir = '../result/FMT_FR/FMT2'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "abd = pd.read_csv('../data/FMT/FMT2/Eric_abd.tsv', sep='\\t', header=0, index_col=0)\n",
    "name_dict = {}\n",
    "for sp in d_df.columns:\n",
    "        name_dict[sp] = sp.replace('_', '-')\n",
    "d_df = d_df.rename(columns=name_dict, index=name_dict)\n",
    "abd = abd.rename(columns=name_dict)\n",
    "profile = abd[list(set(abd.columns).intersection(set(d_df.columns)))]\n",
    "profile = profile.div(profile.sum(axis=1), axis=0)\n",
    "profile = profile.rename(index={'FMT5':'FMT05', 'FMT6': 'FMT06'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR for all samples at all timepoints\n",
    "fr_df = multisample_fr(profile, d_df, node_leaves)\n",
    "fr_df = fr_df.T\n",
    "fr_df = fr_df.drop('nroot')\n",
    "sample_name = '{}_day{}_{}'\n",
    "triads_new = triads.set_index('pre_sample', inplace=False)\n",
    "fr_df_result = pd.DataFrame(index=fr_df.index)\n",
    "for idx in frac_df.index:\n",
    "    ori_sname = frac_df.loc[idx, 'sname']\n",
    "    new_sname = sample_name.format(idx, 0, ori_sname)\n",
    "    days = triads_new.loc[ori_sname, 'days'].split(',')\n",
    "    samples = triads_new.loc[ori_sname, 'post_samples'].split(',')\n",
    "    fr_df_result[new_sname] = fr_df[ori_sname]\n",
    "    for i, d in enumerate(days):\n",
    "        fr_df_result[sample_name.format(idx, d, samples[i])] = fr_df[samples[i]]  \n",
    "fr_df_result.to_csv(os.path.join(outdir, 'fr.tsv'), sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr_r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
