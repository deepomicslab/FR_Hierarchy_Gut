{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 97)\n",
      "(4324, 97)\n"
     ]
    }
   ],
   "source": [
    "# This procedure aims to analyze the NAFLD dataset using NAFLD GCN\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import abd_profile\n",
    "import GCN\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import analysis\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load data of NAFLD\n",
    "ori_profile = abd_profile.input_profile('../data/NAFLD/abd.tsv' , transfer=True)\n",
    "ori_GCN = GCN.input_GCN('../data/NAFLD/NASH_GCN.tsv', transfer=True)\n",
    "print(ori_profile.shape)\n",
    "print(ori_GCN.shape)\n",
    "metadata = pd.read_csv('../data/NAFLD/NASH_forward_63_map.txt', sep = '\\t', header=0, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the distance\n",
    "d_df = GCN.sp_d(ori_GCN)\n",
    "params = {\n",
    "    'sample cluster': 'enterotype', # 'enterotype', # can be 'seat'\n",
    "    'max_cluster': 10,\n",
    "    'max_depth': 6\n",
    "}\n",
    "d_df.to_csv('../data/NAFLD/NASH_distance.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../result/NAFLD'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# split samples according to phenotype\n",
    "cluster_labels = list(set(metadata['DiseaseStatus']))\n",
    "label_dict = {}\n",
    "cluster_profiles = {}\n",
    "phenos = ['NASH', 'Normal']\n",
    "for pheno in phenos:\n",
    "    idx_list = list(metadata[metadata['DiseaseStatus'] == pheno].index)\n",
    "    cluster_profiles[pheno] = copy.deepcopy(ori_profile.loc[idx_list, :])\n",
    "\n",
    "# build personalized functional redundancy network and construct the tree for each phenotypes\n",
    "# find the keystone speceis and keystone clsuter\n",
    "result, c = analysis.main(ori_GCN, ori_profile, outdir, params, d_df, cluster_profiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common: 6 species: \n",
      "s__A. ruminis-OTU75\n",
      "s__B. barnesiae\n",
      "s__B. caecicola-OTU4\n",
      "s__B. producta-OTU32\n",
      "s__F. prausnitzii-OTU8\n",
      "s__F. prausnitzii-OTU80\n",
      "\n",
      "In 15 only: NASH species: \n",
      "s__A. octavius\n",
      "s__B. coprophilus\n",
      "s__C. pinnipediorum\n",
      "s__D. pneumosintes\n",
      "s__E. peruensis\n",
      "s__Escherichia-Shigella-OTU88\n",
      "s__Ezakiella-OTU94\n",
      "s__F. magna\n",
      "s__P. buccalis\n",
      "s__P. ivorii\n",
      "s__P. lacrimalis\n",
      "s__P. loveana\n",
      "s__P. olsenii\n",
      "s__P. sp. 2007b\n",
      "s__S5-A14a-OTU76\n",
      "\n",
      "In 19 only: Normal species: \n",
      "s__A. caccae\n",
      "s__A. indistinctus-OTU57\n",
      "s__B. caecicola-OTU51\n",
      "s__B. coprosuis-OTU67\n",
      "s__B. hydrogenotrophica\n",
      "s__B. magnum\n",
      "s__B. producta-OTU81\n",
      "s__C. comes\n",
      "s__D. formicigenerans\n",
      "s__D. longicatena\n",
      "s__E. oxidoreducens\n",
      "s__F. saccharivorans\n",
      "s__P. chartae-OTU69\n",
      "s__R. gnavus\n",
      "s__R. torques\n",
      "s__Ruminiclostridium-OTU96\n",
      "s__Ruminococcaceae-OTU46\n",
      "s__S. variabile-OTU44\n",
      "s__S. variabile-OTU93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the difference of keystone speceis and keystone cluster\n",
    "sp_dict  = {}\n",
    "for pheno in phenos:\n",
    "    cdir = os.path.join(outdir, 'cluster_{}'.format(pheno))\n",
    "    keystone_path = os.path.join(cdir, 'keystone_node.tsv')\n",
    "    keystone_df = pd.read_csv(keystone_path, sep='\\t', header=0, index_col=0)\n",
    "    keystone_cluster  = (keystone_df[(keystone_df['is_keystone'] == True) & (keystone_df['layer'] == 1)])['leaves'].iloc[0].split(',')\n",
    "    sp_dict[pheno] = copy.deepcopy(set(keystone_cluster))\n",
    "\n",
    "common = sp_dict[phenos[0]].intersection(sp_dict[phenos[1]])\n",
    "diff0 = sp_dict[phenos[0]].difference(sp_dict[phenos[1]])\n",
    "diff1 = sp_dict[phenos[1]].difference(sp_dict[phenos[0]])\n",
    "\n",
    "print('Common: {} species: \\n{}\\n'.format(len(common), '\\n'.join(sorted(list(common)))))\n",
    "print('In {} only: {} species: \\n{}\\n'.format(len(diff0), phenos[0], '\\n'.join(sorted(list(diff0)))))\n",
    "print('In {} only: {} species: \\n{}\\n'.format(len(diff1), phenos[1], '\\n'.join(sorted(list(diff1)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
