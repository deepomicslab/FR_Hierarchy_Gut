{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is for mutiple regression on nFR, days after FMT and fraction at each cluster/supercluster.\n",
    "\n",
    "FMT dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for mutiple regression on nFR, days after FMT and fraction at each cluster/supercluster.\n",
    "# FMT dataset 2\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import tree_util\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frac_df = pd.read_csv('../data/FMT/FMT2/Eric.txt', sep='\\t', header=0, index_col=0)\n",
    "deltat = pd.read_csv('../data/FMT/FMT2/deltat.txt', sep='\\t', header=0, index_col=0)\n",
    "triads = pd.read_csv('../data/FMT/FMT2/triads.txt', sep='\\t', header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in triads.index:\n",
    "    posts = triads.loc[idx, 'post_samples'].strip().split(',')\n",
    "    times = []\n",
    "    for p in posts:\n",
    "        if p not in deltat.index:\n",
    "            print(p)\n",
    "        else:\n",
    "            times.append(str(deltat.loc[p, 'delta_t']))\n",
    "    t_str = ','.join(times)\n",
    "    triads.loc[idx, 'days'] = t_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in frac_df.index:\n",
    "    d = frac_df.loc[idx, 'Days postFMT']\n",
    "    cand = triads[triads['days'] == d]['pre_sample']\n",
    "    ids = triads[triads['days'] == d].index\n",
    "    if len(cand) == 1:\n",
    "        #print(list(cand))\n",
    "        s = list(cand)[0]\n",
    "        frac_df.loc[idx, 'sname'] = s\n",
    "        triads.loc[list(ids)[0], 'alias'] = idx\n",
    "triads.loc[10, 'alias'] = 'FMT5' \n",
    "s = triads.loc[10, 'pre_sample']\n",
    "frac_df.loc['FMT5', 'sname'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nFR for a sample\n",
    "def nfr_value(d_df, profile, sname):\n",
    "    sp_list = list(profile.columns)\n",
    "    n = len(sp_list)\n",
    "    corr = np.ones(shape=(n, n)) - d_df.loc[sp_list, sp_list].values\n",
    "    np.fill_diagonal(corr, 0)\n",
    "    # print(corr[1, 1])\n",
    "    a = np.array(profile.loc[sname, sp_list])\n",
    "    inter_matrix = np.dot(a.reshape(len(a), 1),a.reshape(1, len(a)))\n",
    "    np.fill_diagonal(inter_matrix, 0)\n",
    "    td = np.sum(inter_matrix)/2\n",
    "    fr = np.sum(np.multiply(inter_matrix, corr))/2\n",
    "    fd = np.sum(np.multiply(inter_matrix, d_df.loc[sp_list, sp_list].values))/2\n",
    "    if td == 0:\n",
    "        return 0\n",
    "    return fr/td\n",
    "\n",
    "# compute nFR for all sample\n",
    "def multisample_nfr(profile, d_df, node_leaves):\n",
    "    result = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    for sname in profile.index:\n",
    "       for node, sp_list in node_leaves.items():\n",
    "           sp_list = list(set(sp_list).intersection(set(profile.columns)))\n",
    "           selected_d = d_df.loc[sp_list, sp_list]\n",
    "           selected_profile = profile.loc[:, sp_list]\n",
    "           value = nfr_value(selected_d, selected_profile, sname)\n",
    "           result.loc[sname, node] = value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tree\n",
    "with open('../result/GCN_fix_tree/renamed_GCN_tree.newick') as fp:\n",
    "    newick_tree = fp.read()\n",
    "    # newick_tree = newick_tree.replace('-', '_')\n",
    "    \n",
    "# construct tree with newick string\n",
    "json_tree = tree_util.parse(newick_tree)\n",
    "largest = {'largest': 0}\n",
    "leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "largest_level = largest['largest']\n",
    "nlayer = largest_level\n",
    "layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "\n",
    "tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "leaves_dict = copy.deepcopy(layer_leaves_dict)\n",
    "\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "node_leaves = {}\n",
    "for level in layer_leaves_dict.keys():\n",
    "    for node, sp_list in layer_leaves_dict[level].items():\n",
    "        if node in node_leaves.keys():\n",
    "            continue\n",
    "        node_leaves[node] = copy.deepcopy(sp_list)\n",
    "subtree_nodes = {}\n",
    "for l in leaf_list:\n",
    "    parent = parent_dict[l]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent].append(l)\n",
    "\n",
    "for node in node_leaves.keys():\n",
    "    parent = parent_dict[node]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent] += subtree_nodes[node]\n",
    "    subtree_nodes[parent].append(node)\n",
    "\n",
    "for node in subtree_nodes.keys():\n",
    "    subtree_nodes[node].append(node)\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)\n",
    "\n",
    "node_leaves['root'] = copy.deepcopy(leaf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance, abundance profile and metadata\n",
    "outdir = '../result/FMT/nFR/FMT2'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "param = 0.5\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "abd = pd.read_csv('../data/FMT/FMT2/Eric_abd.tsv', sep='\\t', header=0, index_col=0)\n",
    "name_dict = {}\n",
    "for sp in d_df.columns:\n",
    "        name_dict[sp] = sp.replace('_', '-')\n",
    "d_df = d_df.rename(columns=name_dict, index=name_dict)\n",
    "abd = abd.rename(columns=name_dict)\n",
    "profile = abd[list(set(abd.columns).intersection(set(d_df.columns)))]\n",
    "profile = profile.div(profile.sum(axis=1), axis=0)\n",
    "\n",
    "profile = profile.rename(index={'FMT5':'FMT05'})\n",
    "pre_slist = list(frac_df['sname'])\n",
    "profile = profile.loc[pre_slist,]\n",
    "rename_dict = {}\n",
    "for idx in frac_df.index:\n",
    "    rename_dict[frac_df.loc[idx, 'sname']] = idx\n",
    "profile.rename(index=rename_dict).to_csv(os.path.join(outdir, 'abd.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nFR for all samples at timepoint 0\n",
    "nfr_df = multisample_nfr(profile, d_df, node_leaves)\n",
    "nfr_df = nfr_df.T\n",
    "nfr_df = nfr_df.drop('nroot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cutoff = 0.05\n",
    "# prepare frac and t for regression\n",
    "frac = []\n",
    "t = []\n",
    "sname_list = []\n",
    "for idx in frac_df.index:\n",
    "    sname = frac_df.loc[idx, 'sname']\n",
    "    t_str = frac_df.loc[idx, 'Days postFMT']\n",
    "    frac_str = frac_df.loc[idx, 'Fraction of donor specific strains']\n",
    "    t += [int(ts) for ts in t_str.split(',')]\n",
    "    frac += [float(f) for f in frac_str.split(',')]\n",
    "    sname_list += [sname]*len(t_str.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "odf = pd.DataFrame(columns=['F-pvalue', 'nfr_co', 't_co', 'const_co', 'nfr_p', 't_p', 'const_p'])\n",
    "for node in node_leaves.keys():\n",
    "    nfr = []\n",
    "    for sname in sname_list:\n",
    "        value = nfr_df.loc[node, sname]\n",
    "        nfr.append(value)\n",
    "    if sum(nfr) == 0:\n",
    "        continue\n",
    "    df = pd.DataFrame()\n",
    "    df['frac'] = frac\n",
    "    df['nfr'] = nfr\n",
    "    df['t'] = t\n",
    "\n",
    "    X = df[['nfr', 't']]\n",
    "    y = df['frac']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    odf.loc[node, 'F-pvalue'] = result.f_pvalue\n",
    "    for var in result.pvalues.index:\n",
    "        odf.loc[node, \"{}_co\".format(var)] = result.params[var]\n",
    "        odf.loc[node, \"{}_p\".format(var)] = result.pvalues[var]\n",
    "odf.sort_values(by='F-pvalue').to_csv(os.path.join(outdir, 'p_values.tsv'), index=True, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-pvalue</th>\n",
       "      <th>nfr_co</th>\n",
       "      <th>t_co</th>\n",
       "      <th>const_co</th>\n",
       "      <th>nfr_p</th>\n",
       "      <th>t_p</th>\n",
       "      <th>const_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C3</th>\n",
       "      <td>0.015189</td>\n",
       "      <td>-0.442987</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.653932</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.57552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C4</th>\n",
       "      <td>0.004133</td>\n",
       "      <td>1.049201</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>-0.094378</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.581792</td>\n",
       "      <td>0.55523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C5</th>\n",
       "      <td>0.025254</td>\n",
       "      <td>-0.535224</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.760055</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.543664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C10</th>\n",
       "      <td>0.014077</td>\n",
       "      <td>-0.470651</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.516373</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.923037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C15</th>\n",
       "      <td>0.001985</td>\n",
       "      <td>-0.402447</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.26274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S2-C5</th>\n",
       "      <td>0.032318</td>\n",
       "      <td>-0.581848</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.787635</td>\n",
       "      <td>0.00928</td>\n",
       "      <td>0.814373</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_C7</th>\n",
       "      <td>0.04425</td>\n",
       "      <td>-0.296316</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.507224</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.98547</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supercluster_S1</th>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.863652</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.289235</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.604101</td>\n",
       "      <td>0.092531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F-pvalue    nfr_co      t_co  const_co     nfr_p       t_p  \\\n",
       "cluster_S1-C3    0.015189 -0.442987  0.000551  0.653932  0.004056   0.57552   \n",
       "cluster_S1-C4    0.004133  1.049201  0.000521 -0.094378     0.001  0.581792   \n",
       "cluster_S1-C5    0.025254 -0.535224  0.000609  0.760055  0.007071  0.543664   \n",
       "cluster_S1-C10   0.014077 -0.470651 -0.000094  0.516373  0.003734  0.923037   \n",
       "cluster_S1-C15   0.001985 -0.402447  0.001078  0.577465  0.000459   0.26274   \n",
       "cluster_S2-C5    0.032318 -0.581848  0.000233  0.787635   0.00928  0.814373   \n",
       "cluster_C7        0.04425 -0.296316 -0.000018  0.507224  0.013157   0.98547   \n",
       "supercluster_S1  0.000269  1.863652 -0.000456 -0.289235  0.000056  0.604101   \n",
       "\n",
       "                  const_p  \n",
       "cluster_S1-C3         0.0  \n",
       "cluster_S1-C4     0.55523  \n",
       "cluster_S1-C5         0.0  \n",
       "cluster_S1-C10        0.0  \n",
       "cluster_S1-C15        0.0  \n",
       "cluster_S2-C5         0.0  \n",
       "cluster_C7            0.0  \n",
       "supercluster_S1  0.092531  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf[odf['F-pvalue']<p_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regression results\n",
    "formula_tmp = r'$f_{{ds}} = {:.4f}*nFR_{{pre}} + {:.4f}*t_{{post}} + {:.4f}$' + '\\np = {:.4}'\n",
    "\n",
    "for node in sorted(list(odf.index)):\n",
    "    nfr_co = odf.loc[node, 'nfr_co']\n",
    "    t_co = odf.loc[node, 't_co']\n",
    "    const = odf.loc[node, 'const_co']\n",
    "    p_value = odf.loc[node, 'F-pvalue']\n",
    "    nfr = np.linspace(0, max(max(nfr_df.loc[node, ])*1.1, 0.05), 1000)\n",
    "    t = np.linspace(0, 150, 1000)\n",
    "    X, Y = np.meshgrid(nfr, t)\n",
    "    f = nfr_co*X + t_co*Y + const\n",
    "    f[f>1] = np.nan\n",
    "    f[f<0] = np.nan\n",
    "    formula = formula_tmp.format(nfr_co, t_co, const, p_value)\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    cmp = plt.cm.YlGnBu_r\n",
    "    surf = ax.plot_surface(X, Y, f, cmap=cmp, alpha=0.5)\n",
    "    surf.set_clim(0, 1)\n",
    "    ax.set_yticks(np.arange(0, 150, 50))\n",
    "    ax.set_yticklabels(np.arange(0, 150, 50))\n",
    "\n",
    "    ax.set_zlim((0, 1))\n",
    "    ax.set_zticks(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "    ax.set_zticklabels(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "\n",
    "    ax.set_xlabel(r'$nFR_{pre}$', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel(r'$t_{post}$', fontweight='bold', fontsize=14)\n",
    "    ax.zaxis.set_rotate_label(False) \n",
    "    ax.set_zlabel(r'$f_{ds}$', fontweight='bold', fontsize=14)\n",
    "\n",
    "    nfr = []\n",
    "    frac = []\n",
    "    t = []\n",
    "    colors = []\n",
    "    slist = []\n",
    "    for sname in frac_df.index:\n",
    "        sname2 = frac_df.loc[sname, 'sname']\n",
    "        t_str = frac_df.loc[sname, 'Days postFMT']\n",
    "        frac_str = frac_df.loc[sname, 'Fraction of donor specific strains']\n",
    "        n_t = len(t_str.split(','))\n",
    "        t += [int(ts) for ts in t_str.split(',')]\n",
    "        frac += [float(f) for f in frac_str.split(',')]\n",
    "        #c += [color_dict[int(sname[3:])]] * n_t\n",
    "        colors += [int(sname[3:])-1] * n_t\n",
    "        nfr += [nfr_df.loc[node, sname2]] * n_t\n",
    "        slist += [sname] * n_t\n",
    "\n",
    "    point_df = pd.DataFrame(columns=['sample', 'nFR_pre', 't_post', 'f_ds'])\n",
    "    point_df['sample'] = slist\n",
    "    point_df['nFR_pre'] = nfr\n",
    "    point_df['t_post'] = t\n",
    "    point_df['f_ds'] = frac\n",
    "\n",
    "    point_df.to_csv(os.path.join(outdir, '{}.tsv'.format(node)), sep='\\t', header=True, index=False)\n",
    "\n",
    "    ax.scatter(nfr, t, frac, c = colors, cmap='tab20')\n",
    "    ax.view_init(elev=15, azim=245)\n",
    "    ax.set_title(formula, y = 0.95)\n",
    "    ax.xaxis.set_pane_color((1, 1, 1, 1))\n",
    "    ax.yaxis.set_pane_color((1, 1, 1, 1))\n",
    "    ax.zaxis.set_pane_color((1, 1, 1, 1))\n",
    "    plt.suptitle(node.replace('_', ' '))\n",
    "    # fig.colorbar(surf)\n",
    "    plt.tight_layout()\n",
    "    opath = os.path.join(outdir, '{}.pdf'.format(node))\n",
    "    plt.savefig(opath, dpi=300, format='pdf')\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr_r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
