{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd \n",
    "import random\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.stats.multitest import fdrcorrection as fdr\n",
    "sys.path.append('..')\n",
    "import abd_profile\n",
    "import numpy as np\n",
    "import se\n",
    "import tree_util\n",
    "import copy\n",
    "from scipy import stats\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fr(d_df, profile, sname):\n",
    "    #print(profile.columns, d_df.index)\n",
    "    sp_list = sorted(list(set(profile.columns).intersection(set(d_df.index))))\n",
    "    #print(sp_list)\n",
    "    sp_d_df = d_df.loc[sp_list, sp_list]\n",
    "    #print(profile)\n",
    "    sp_profile = np.array(profile.loc[sname, sp_list])\n",
    "    value = np.dot(sp_profile.reshape(len(sp_profile), 1),sp_profile.reshape(1, len(sp_profile)))\n",
    "    width = value.shape[0]\n",
    "    cor_df = np.ones(shape=(width, width)) - sp_d_df.values\n",
    "    for i in range(width):\n",
    "        cor_df[i][i] = 0\n",
    "    value = np.multiply(value, cor_df)\n",
    "    fr_df = pd.DataFrame(value, index=sp_list, columns=sp_list)\n",
    "    return fr_df\n",
    "\n",
    "def select_edges_assign(df, pairs, remaining_pairs, nsample=200):\n",
    "    triu_indices = np.triu_indices_from(df, k=1)\n",
    "    upper_triangle_values = df.values[triu_indices]\n",
    "    #print(upper_triangle_values)\n",
    "    #samples = random.sample(upper_triangle_values.value(), nsample)\n",
    "    samples = sorted(list(upper_triangle_values), reverse=True)[:nsample]\n",
    "    \n",
    "    # random put into the new_df\n",
    "    new_df = pd.DataFrame(index=df.index, columns=df.columns, data=0)\n",
    "    #upper_triangle_pairs = [(df.index[i], df.columns[j]) for i, j in zip(*triu_indices)]\n",
    "    upper_triangle_pairs = pairs + remaining_pairs\n",
    "    sample_pairs = random.sample(upper_triangle_pairs, nsample)\n",
    "    for idx, (i, j) in enumerate(sample_pairs):\n",
    "        new_df.loc[i, j] = samples[idx]\n",
    "    rand_df = copy.deepcopy(new_df+new_df.T)\n",
    "    \n",
    "   \n",
    "    # random put into the pairs\n",
    "    new_df = pd.DataFrame(index=df.index, columns=df.columns, data=0)\n",
    "    sample_pairs = random.sample(pairs, nsample)\n",
    "    for idx, (i, j) in enumerate(sample_pairs):\n",
    "        new_df.loc[i, j] = samples[idx]\n",
    "    in_df = copy.deepcopy(new_df+new_df.T)\n",
    "\n",
    "    # random put outside the pairs\n",
    "    new_df = pd.DataFrame(index=df.index, columns=df.columns, data=0)\n",
    "    sample_pairs = random.sample(remaining_pairs, nsample)\n",
    "    for idx, (i, j) in enumerate(sample_pairs):\n",
    "        new_df.loc[i, j] = samples[idx]\n",
    "    out_df = copy.deepcopy(new_df+new_df.T)\n",
    "    return rand_df, in_df, out_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n: repeat time\n",
    "# k: sample number\n",
    "\n",
    "def summary(se_list_rand, se_list_high, se_list_low):\n",
    "    \n",
    "    # run paired Wilcoxon test\n",
    "    statistic, p1 = stats.wilcoxon(se_list_high, se_list_rand)\n",
    "    statistic, p2 = stats.wilcoxon(se_list_low, se_list_rand)\n",
    "    statistic, p3 = stats.wilcoxon(se_list_high, se_list_low)\n",
    "    print(\"rand mean: \", np.mean(se_list_rand), 'rand std: ', np.std(se_list_rand))\n",
    "    print(\"high mean: \", np.mean(se_list_high), 'high std: ', np.std(se_list_high))\n",
    "    print(\"low mean: \", np.mean(se_list_low), 'low std: ', np.std(se_list_low))\n",
    "    print(\"rand vs high: \", p1)\n",
    "    print(\"rand vs low: \", p2)\n",
    "    print(\"high vs low: \", p3)\n",
    "\n",
    "def get_ori_nets(profile, d_df):\n",
    "    net_dict = {}\n",
    "    rename_dict = {}\n",
    "    for sp in d_df.index:\n",
    "        rename_dict[sp] = sp.replace('_', '-')\n",
    "    renamed_d = d_df.rename(columns=rename_dict, index=rename_dict)\n",
    "\n",
    "    renamed_profile = profile.rename(columns=rename_dict)\n",
    "    renamed_profile = renamed_profile[list(set(renamed_profile.columns).intersection(set(renamed_d.index)))]\n",
    "    for sname in profile.index:\n",
    "        # print(sname)\n",
    "        edge_df = fr(renamed_d, renamed_profile, sname)\n",
    "        net_dict[sname] = copy.deepcopy(edge_df)\n",
    "        # tmp = se.subtree_se_adj(edge_df, parent_dict, node_leaves, subtree_nodes, direct_children_dict, param)\n",
    "        # for node in tmp.keys():\n",
    "        #     value = tmp[node]\n",
    "        #     result.loc[sname, node] = value\n",
    "    return net_dict\n",
    "\n",
    "def split_newick(newick_tree):\n",
    "    json_tree = tree_util.parse(newick_tree)\n",
    "    largest = {'largest': 0}\n",
    "    leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "    largest_level = largest['largest']\n",
    "    nlayer = largest_level\n",
    "    leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "    layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "\n",
    "    tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "    tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "    result = {}\n",
    "    # compute leaf layer\n",
    "    result['leaves_dict'] = copy.deepcopy(layer_leaves_dict)\n",
    "    parent_dict = {}\n",
    "    tree_util.parents(json_tree, parent_dict)\n",
    "    node_leaves = {}\n",
    "    for level in layer_leaves_dict.keys():\n",
    "        for node, sp_list in layer_leaves_dict[level].items():\n",
    "            if node in node_leaves.keys():\n",
    "                continue\n",
    "            node_leaves[node] = copy.deepcopy(sp_list)\n",
    "    subtree_nodes = {}\n",
    "    for l in leaf_list:\n",
    "        parent = parent_dict[l]\n",
    "        if parent not in subtree_nodes.keys():\n",
    "            subtree_nodes[parent] = []\n",
    "        subtree_nodes[parent].append(l)\n",
    "\n",
    "    for node in node_leaves.keys():\n",
    "        parent = parent_dict[node]\n",
    "        if parent not in subtree_nodes.keys():\n",
    "            subtree_nodes[parent] = []\n",
    "        subtree_nodes[parent] += subtree_nodes[node]\n",
    "        subtree_nodes[parent].append(node)\n",
    "\n",
    "    for node in subtree_nodes.keys():\n",
    "        subtree_nodes[node].append(node)\n",
    "\n",
    "    direct_children_dict = {}\n",
    "    for node, parent in parent_dict.items():\n",
    "        if parent not in direct_children_dict:\n",
    "            direct_children_dict[parent] = []\n",
    "        direct_children_dict[parent].append(node)\n",
    "    return parent_dict, node_leaves, subtree_nodes, direct_children_dict, leaf_list\n",
    "\n",
    "def get_se_list(net_dict, parent_dict, node_leaves, subtree_nodes, direct_children_dict, param=0.5):\n",
    "    result = pd.DataFrame()\n",
    "    for sname in net_dict.keys():\n",
    "        edge_df = net_dict[sname]\n",
    "        # for i, edge_df in enumerate(net_dict[sname]):\n",
    "        #     nid = \"{}_{}\".format(sname, i)\n",
    "        nid = sname\n",
    "        tmp = se.subtree_se_adj(edge_df, parent_dict, node_leaves, subtree_nodes, direct_children_dict, param)\n",
    "        for node in tmp.keys():\n",
    "            value = tmp[node]\n",
    "            result.loc[nid, node] = value\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_cohort(indir, sedir):\n",
    "    # Load the dataset\n",
    "    abd_path = os.path.join(indir, 'abd.tsv')\n",
    "    metadata_path = os.path.join(indir, 'metadata.tsv')\n",
    "    # first process data from gutmeta\n",
    "    raw_profile = abd_profile.input_profile(abd_path, transfer=True)\n",
    "    metadata = pd.read_csv(metadata_path, sep='\\t', header=0)\n",
    "    selected_raw_profile = raw_profile.loc[list(metadata['sample_id']), :]\n",
    "    selected_raw_profile = abd_profile.rename_s_level(selected_raw_profile)\n",
    "    crc_profile = abd_profile.clean(selected_raw_profile)\n",
    "\n",
    "    pheno_list = {}\n",
    "    for i in range(metadata.shape[0]):\n",
    "        pheno = metadata.loc[i, 'disease']\n",
    "        if pheno not in pheno_list.keys():\n",
    "            pheno_list[pheno] = []\n",
    "        if metadata.loc[i, 'sample_id'] in list(crc_profile.index):\n",
    "            pheno_list[pheno].append(metadata.loc[i, 'sample_id'])\n",
    "\n",
    "    # se_dict = {}\n",
    "    # for c in pheno_list.keys():\n",
    "    #     se_dict[c] = pd.read_csv(os.path.join(sedir, 'se_{}.tsv'.format(c)), sep='\\t', header=0, index_col=0)\n",
    "\n",
    "    # se_df = pd.DataFrame()\n",
    "    # for c in pheno_list.keys():\n",
    "    #     se_df = pd.concat([se_df, se_dict[c]], axis=0)\n",
    "\n",
    "    # #slist = pheno_list['Health']\n",
    "    return crc_profile\n",
    "    # return crc_profile[sorted(crc_profile.columns)], se_df.loc[slist, ]\n",
    "\n",
    "def sampling(total, cluster_list, slist):\n",
    "    clusters = random.choices(cluster_list, k=total)\n",
    "    samples = random.choices(slist, k=total)\n",
    "    return samples, clusters\n",
    "\n",
    "def sampling_s(total, slist):\n",
    "    samples = random.choices(slist, k=total)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_dir = '../data'\n",
    "total_time = 10\n",
    "outer_se = '../result/GCN_fix_tree/SE/GCN_tree_diff'\n",
    "output_dir = '../result/validation/se_related_3'\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "# abd_dff_dir = '../result/taxa_abd_check'\n",
    "plist = ['CRC', 'IBD', 'T2D']\n",
    "plist = ['CRC']\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "diff_df = pd.read_csv('../result/GCN_fix_tree/SE/GCN_tree_diff/p_all_cohorts.tsv', sep='\\t', header=0, index_col=0)\n",
    "with open('../result/GCN_fix_tree/renamed_GCN_tree.newick') as fp:\n",
    "    newick_tree = fp.read()\n",
    "    parent_dict, node_leaves, subtree_nodes, direct_children_dict, leaf_list = split_newick(newick_tree)\n",
    "pheno_result= {}\n",
    "ori_se_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CRC ==\n",
      "-- CRC -- CRC1 --\n",
      "-- CRC -- CRC2 --\n",
      "-- CRC -- CRC3 --\n",
      "-- CRC -- CRC4 --\n",
      "-- CRC -- CRC5 --\n",
      "-- CRC -- CRC6 --\n",
      "-- CRC -- CRC7 --\n",
      "-- CRC -- CRC8 --\n",
      "-- CRC -- CRC9 --\n",
      "pairs:  191890\n",
      "remaining pairs:  189611\n"
     ]
    }
   ],
   "source": [
    "cluster = 'supercluster_S1'\n",
    "nsample = 189000\n",
    "for pheno in plist:\n",
    "    result = pd.DataFrame(columns = ['sample', 'cluster', 'rand', 'high', 'low'])\n",
    "    data_dir = os.path.join(outer_dir, pheno)\n",
    "    se_dir = os.path.join(outer_se, pheno)\n",
    "    print('== {} =='.format(pheno))\n",
    "    merged_crc_profile = pd.DataFrame()\n",
    "    for cohort in os.listdir(data_dir):\n",
    "        print(f'-- {pheno} -- {cohort} --')\n",
    "        # sp_diff_df = pd.read_csv(os.path.join(abd_dff_dir, pheno, 'p_{}.tsv'.format(cohort)), sep='\\t', header=0, index_col=0)\n",
    "        se_cohort_dir = os.path.join(se_dir, cohort)\n",
    "        #ori_se = pd.read_csv(os.path.join(se_cohort_dir, 'se_Health.tsv'), sep='\\t', header=0, index_col=0)\n",
    "        abd_dir = os.path.join(data_dir, cohort)\n",
    "        #crc_profile, se_df = read_cohort(abd_dir, os.path.join(outer_se, pheno, cohort))\n",
    "        crc_profile = read_cohort(abd_dir, os.path.join(outer_se, pheno, cohort))\n",
    "        merged_crc_profile, crc_profile_tmp = merged_crc_profile.align(crc_profile, join='outer', fill_value=0)\n",
    "        merged_crc_profile.loc[crc_profile.index, crc_profile.columns] = crc_profile\n",
    "    #random sampling sample and cluster \n",
    "    #sub_slist, sub_clusters = sampling(total_sample, clusters, merged_crc_profile.index)  \n",
    "    sub_slist = sampling_s(total_time, merged_crc_profile.index) \n",
    "    crc_profile = merged_crc_profile.loc[list(set(sub_slist)), ]\n",
    "    crc_profile = crc_profile[list(set(crc_profile.columns).intersection(set(d_df.index)))]\n",
    "    fr_dict = copy.deepcopy(get_ori_nets(crc_profile, d_df))\n",
    "    renamed_dict = {}\n",
    "    for sp in crc_profile.columns:\n",
    "        renamed_dict[sp] = sp.replace('_', '-')\n",
    "    crc_profile = crc_profile.rename(columns=renamed_dict)\n",
    "    \n",
    "    leaves = set(node_leaves[cluster]).intersection(set(crc_profile.columns))\n",
    "    leaves = sorted(list(leaves))\n",
    "    pairs = []\n",
    "    for i in range(len(leaves)):\n",
    "        for j in range(i+1, len(leaves)):\n",
    "            pairs.append((leaves[i], leaves[j]))\n",
    "    print('pairs: ', len(pairs))\n",
    "\n",
    "    remaining_pairs = []\n",
    "    for i in range(len(crc_profile.columns)):\n",
    "        s1 = crc_profile.columns[i]\n",
    "        for j in range(i+1, len(crc_profile.columns)):\n",
    "            s2 = crc_profile.columns[j]\n",
    "            if not ((s1 in leaves) and (s2 in leaves)):\n",
    "                remaining_pairs.append((s1, s2))\n",
    "    print('remaining pairs: ', len(remaining_pairs))\n",
    "    rand_dict = {}\n",
    "    high_dict = {}\n",
    "    low_dict = {}\n",
    "    for subid in range(len(sub_slist)):\n",
    "        sample = sub_slist[subid]\n",
    "        tmp_dict = {}\n",
    "        tmp_dict[sample] = copy.deepcopy(fr_dict[sample])\n",
    "        rand_df, in_df, out_df = select_edges_assign(fr_dict[sample], pairs, remaining_pairs, nsample)\n",
    "        rand_dict[sample] = copy.deepcopy(rand_df)\n",
    "        high_dict[sample] = copy.deepcopy(in_df)\n",
    "        low_dict[sample] = copy.deepcopy(out_df)\n",
    "    # rand_se = get_se_list(rand_dict, parent_dict, node_leaves, subtree_nodes, direct_children_dict)\n",
    "    # high_se = get_se_list(high_dict, parent_dict, node_leaves, subtree_nodes, direct_children_dict)\n",
    "    # low_se = get_se_list(low_dict, parent_dict, node_leaves, subtree_nodes, direct_children_dict)\n",
    "    # for  nid in rand_se.index:\n",
    "    #     result = result.append({'sample': nid, 'cluster': cluster, 'rand': rand_se.loc[nid, cluster], 'high': high_se.loc[nid, cluster], 'low': low_se.loc[nid, cluster]}, ignore_index=True)\n",
    "    \n",
    "    # tmp_dir = os.path.join(output_dir, pheno)\n",
    "    # if not os.path.exists(tmp_dir):\n",
    "    #     os.makedirs(tmp_dir)\n",
    "    # result.to_csv(os.path.join(tmp_dir, 'se_summary.tsv'), sep='\\t')\n",
    "    # pheno_result[pheno] = copy.deepcopy(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_se = get_se_list(rand_dict, parent_dict, node_leaves, subtree_nodes, direct_children_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_se = get_se_list(high_dict, parent_dict, node_leaves, subtree_nodes, direct_children_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_se = get_se_list(low_dict, parent_dict, node_leaves, subtree_nodes, direct_children_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x258731c1f10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWsElEQVR4nO3df3DU9Z3H8debGE0MDGEgBSFqwuiAAkHi1qEi6Zy00R62FWfqSKfXsdritFzJMTd06nUO0JmbdiptpTdtb6i1daZq4TAythF1rLXYsecZQFF+nS1STQw0omDlkiPE9/2xCWTjhuyS7+73s9nnY6aT5Lub3TffZl9+vp/P+/v9mrsLABCuMXEXAAA4M4IaAAJHUANA4AhqAAgcQQ0AgTsnFy86adIkr6mpycVLA8CotH379rfdvSrdYzkJ6pqaGrW2tubipQFgVDKzvwz1GFMfABA4ghoAAkdQA0DgcjJHDQDZ6unpUVtbm7q7u+MuJafKyspUXV2t0tLSjH+HoAYQhLa2No0bN041NTUys7jLyQl315EjR9TW1qba2tqMf4+gBhCE7u7ugg3pd//3hA4f69aJ3g90bskYTR5fpgnnn/uh55mZJk6cqM7Ozqxen6AGEIxCDen2d7v0Qd+VSE/0fqD2d7skaciwzhaLiQAwAoePdZ8K6X4fuOvwsejm2gnqAG3Z2a4F33lGtd9s0YLvPKMtO9vjLgkoCgcPHtTs2bM/tH316tV6+umn0/7Oid4PJEk/+f539MB//PuHtkeBqY/AbNnZrjubX1FXT68kqf1ol+5sfkWSdOO8aXGWBhStu+++e8jHzi0ZkzaUzy2JbhzMiDow9zy5/1RI9+vq6dU9T+6PqSIgTLk68uzt7dVXvvIVzZo1S42Njerq6tKtt96qzZs3S5Ief/xxzZw5U1deeaVWrFihpttu0Zi+eec/v7Zft3/uBv39giu05cH7IqlHIqiD89bRrqy2A8Wo/8iz/WiXXKePPKMI69dee03Lly/X7t27VVlZqUceeeTUY93d3brjjju0detWbd++XZ2dnSotGaNpE8pVYqaDf/4f/ezhR/Xsc8/rnm//m3p6ekZcj0RQB2dqZXlW24FilMsjz9raWl1xxRWSpCuvvFIHDx489di+ffs0ffr0Uz3QS5culZTs7pg07jx9bslnVVdTpUsumqqPfOQjOnz48IjrkQjq4Ky6bobKS0tStpWXlmjVdTNiqggITy6PPM8777xT35eUlOjkyZN5+d0zIagDc+O8afr2TXM0rbJcJmlaZbm+fdMcFhKBAeI68pwxY4YOHDhwapS9cePGnL5fP7o+AnTjvGkEM3AGq66bkdIdJeXnyLO8vFw//vGPdf3116uiokIf/ehHc/p+/cwHNWpHIZFIODcOAJCNvXv36rLLLsv4+Vt2tuueJ/frraNdmlpZrlXXzcjLAOf999/X2LFj5e5avny5Lr30Uq1cuTKr10j3bzWz7e6eSPd8RtQAzkpcQdkvriPPn/70p3rggQd04sQJzZs3T3fccUfO35OgBpC1Yj4xa+XKlVmPoEeKxUQAWePErPxiRA1kKO5D/ZBwYlZ+EdQYEsF0WjEf6qcztbJc7WlCmROzcoOpD6SVy1N0CxGH+qk4MSu/CGqkRTCl4lA/FSdmZaampkZvv/32iF+HqQ+kRTCl4lD/w0b7iVnuLnfXmDHxj2czqsDMVprZbjN71cweNrOyXBeGeHFxqFQc6gdo1ybpB7OltZXJr7s2jfglDx48qBkzZuiLX/yiZs+erdtvv12JREKzZs3SmjVrTj2vpqZGa9asUX19vebMmaN9+/ZJko4cOaLGxkbNmjVLX/7ylxXVCYXDBrWZTZO0QlLC3WdLKpF0SyTvjmCFFEwh3PGGQ/3A7Nok/XqFdOxNSZ78+usVkYT1a6+9pq997WvavXu3vve976m1tVW7du3S73//e+3atevU8yZNmqQdO3boq1/9qtatWydJuuuuu3TNNddo9+7dWrJkid54440R1yNlPvVxjqRyM+uRdL6ktyJ5dwSrP4Di7voIqdtitB/qF5Tf3i31DJqK6ulKbq+7eUQvffHFF2v+/PmSpE2bNmnDhg06efKkOjo6tGfPHtXV1UmSbrrpJknJS6E2NzdLkrZt23bq+8WLF2vChAkjqqXfsEHt7u1mtk7SG5K6JD3l7k8Nfp6ZLZO0TJIuuuiiSIpDvEIIpjMtasZdG2J0rC277VmoqKiQJL3++utat26dXnzxRU2YMEG33nqrurtP37C2/5KmUV7OdCiZTH1MkPRZSbWSpkqqMLMvDH6eu29w94S7J6qqqqKvFEWJRU2kNb46u+1n4b333lNFRYXGjx+vw4cPa+vWrcP+TkNDgx566CFJ0tatW/Xuu+9GUksmi4mfkPS6u3e6e4+kZklXR/LuwDBY1ERai1ZLpYP+BkrLk9sjMnfuXM2bN08zZ87U5z//eS1YsGDY31mzZo22bdumWbNmqbm5ObLZhUzmqN+QNN/Mzldy6mORJK5hiryI67rDCFz/PPRv705Od4yvTob0COena2pq9Oqrr576+Re/+EXa5w28PVcikdCzzz4rSZo4caKeeupDM8Mjlskc9QtmtlnSDkknJe2UtCHySoA0QlnURIDqbh5xMBeKjLo+3H2NpDXDPhHIgRAWNYE4xX/KDQDgjAhqAAgcQQ0AgSOoASBwBDUA9Bk7dmzcJaTFZU4H4a4mAELDiHoA7moCFI6WAy1q3Nyougfq1Li5US0HWiJ7bXfXqlWrNHv2bM2ZM0cbN26UJC1fvlyPPfaYJGnJkiW67bbbJEn333+/vvWtb0X2/oMR1ANwVxOgMLQcaNHa59eq43iHXK6O4x1a+/zayMK6ublZL730kl5++WU9/fTTWrVqlTo6OrRw4UI999xzkqT29nbt2bNHkvTcc8+poaEhkvdOh6AegAsAAYVh/Y716u7tTtnW3dut9TvWR/L6f/jDH7R06VKVlJRo8uTJ+vjHP64XX3zxVFDv2bNHl19+uSZPnqyOjg798Y9/1NVX5+4SSMxRD8DtloDCcOj4oay2R2XatGk6evSonnjiCTU0NOidd97Rpk2bNHbsWI0bNy5n78uIeoCQ7moCYGhTKqZktT1bCxcu1MaNG9Xb26vOzk5t27ZNV111lSRp/vz5uvfee9XQ0KCFCxdq3bp1WrhwYSTvOxSCegButwQUhqb6JpWVpN66taykTE31TZG8/pIlS1RXV6e5c+fq2muv1Xe/+11NmZL8j8DChQt18uRJXXLJJaqvr9c777yT86C2qG6+OFAikfDW1uyuhEpbHFDc9u7dq8suuyzj57ccaNH6Het16PghTamYoqb6Ji2evjiHFUYn3b/VzLa7eyLd84OYow7pvngACsPi6YsLJphHKoipD9riAGBoQQQ1bXEApOSJJqPd2fwbg5j6oC0OyNxoXc8pKyvTkSNHNHHiRJlZ3OXkhLvryJEjKisrG/7JAwQR1NwXD8jMaF7Pqa6uVltbmzo7O+MuJafKyspUXZ3d3dKDCGruiwdk5kzrOYX+eSktLVVtbW3cZQQpiKCWuC8ekAnWc4pTEIuJADIz1LoN6zmjG0ENFBAuc1Ccgpn6ADA81nOK07BBbWYzJG0csGm6pNXufm+uigIwNNZzis+wQe3u+yVdIUlmViKpXdKjuS0LANAv2znqRZL+7O5/yUUxAIAPyzaob5H0cLoHzGyZmbWaWetob1gHgHzKOKjN7FxJn5H0n+ked/cN7p5w90RVVVVU9QFA0ctmRP0pSTvc/XCuigEAfFg2Qb1UQ0x7AAByJ6OgNrMKSZ+U1JzbcgAAg2V0wou7H5c0Mce1AADS4BRyAAgcQQ0AgSOoASBwBDUABI6gBoDAEdQAEDiCGgACR1ADQOAIagAIHEENACO1a5P0g9nS2srk112bIn157pkIACOxa5P06xVST1fy52NvJn+WpLqbI3kLRtQAMBK/vft0SPfr6UpujwhBDQAjcawtu+1ngaAGgJEYX53d9rNAUAPASCxaLZWWp24rLU9ujwhBHaIcryADiFDdzdKnfyiNv1CSJb9++oeRLSRKdH2EJw8ryMBosWVnu+55cr/eOtqlqZXlWnXdDN04b1r+C6m7OaefT0bUocnDCjIwGmzZ2a47m19R+9EuuaT2o126s/kVbdnZHndpkSOoQ5OHFWRgNLjnyf3q6ulN2dbV06t7ntwfU0W5Q1CHJg8ryMBo8NbRrqy2FzKCOjR5WEEGRoOpleVZbS9kBHVo8rCCDEQi5u6kVdfNUHlpScq28tISrbpuRl7ryAe6PkKU4xVknKVdm5KLusfaklNRi1YX7/9PAXQn9Xd3BNH1kWPm7pG/aCKR8NbW1shfF4jN4GCSklNSxXq084PZyXAebPyF0spX81/PKGBm2909ke6xjKY+zKzSzDab2T4z22tmH4u2RCBwtE2mojsprzKdo14v6Ql3nylprqS9uSsJCBDBlIrupLwaNqjNbLykBkk/kyR3P+HuR3NcFxAWgikV3Ul5lcmIulZSp6Sfm9lOM7vPzCoGP8nMlplZq5m1dnZ2Rl4oECuCKRXdSXk17GKimSUk/ZekBe7+gpmtl/Seu//rUL/DYuIoQZdDKvYHcuhMi4mZtOe1SWpz9xf6ft4s6ZtRFYdABdB+FRzaJhGTYac+3P2QpDfNrL+LfJGkPTmtCvELqcuBy76iyGV6wsvXJT1oZudKOiDpS7krCUEIpcuBkT2QWXueu7/k7gl3r3P3G9393VwXhpiF0uUQ0sgeiAnX+kB6oXQ5hDKyB2JEUCO9UNqvQhnZAzHiokwYWghdDotWp7/GRrH2L6MoMaIejA6DsIQysgdixIh6IDoMwhTCyB6IESPqgegwABAggnogOgwABIigHogOAwABIqgHCqV3GAAGIKgHosMAQIDo+hiMDgMAgWFEDQCBI6gBIHAENVBoOHu26IQzR81tjoDhcfZsUQpjRN3/x3fsTUl++o+PkQKQirNni1IYQc0fH5AZzp5NVSTTQGEENX98QGY4e/a0IjoSDyOo+eMDMsPZs6cV0ZF4GEHNHx+QGc6ePa2IjsTD6Pro/yOj6wMYHmfPJo2v7pv2SLN9lAkjqCX++ABkp4hu0xbG1AcAZKuIpoEyGlGb2UFJf5PUK+mkuydyWRQAZKRIjsSzmfr4O3d/O2eVAADSYuoDAAKXaVC7pKfMbLuZLUv3BDNbZmatZtba2dkZXYUAUOQyDepr3L1e0qckLTezhsFPcPcN7p5w90RVVVWkRQJAMcsoqN29ve/rXyU9KumqXBYFADht2KA2swozG9f/vaRGSa/mujAAQFImXR+TJT1qZv3Pf8jdn8hpVQCAU4YNanc/IGluHmoBAKRBex4ABI6gBoDAEdQAEDiCGgACR1ADQOAIagAIHEENAIEjqAEgcAQ1AASOoAaAwBHUABA4ghoAAkdQA0DgCGoACBxBDQCBI6gBIHAENQAEjqAGgMAR1AAQOIIaAAJHUANA4AhqAAgcQQ0Agcs4qM2sxMx2mtlvclkQACBVNiPqJkl7c1UIACC9jILazKolLZZ0X27LAQAMlumI+l5J35D0wVBPMLNlZtZqZq2dnZ1R1AYABaHlQIsaNzeq7oE6NW5uVMuBlkhff9igNrMbJP3V3bef6XnuvsHdE+6eqKqqiqxAAAhZy4EWrX1+rTqOd8jl6jjeobXPr400rDMZUS+Q9BkzOyjpV5KuNbNfRlYBABSw9TvWq7u3O2Vbd2+31u9YH9l7DBvU7n6nu1e7e42kWyQ94+5fiKwCAChgh44fymr72aCPGgBGYErFlKy2n42sgtrdn3X3GyJ7dwAocE31TSorKUvZVlZSpqb6psje45zIXgkAitDi6YslJeeqDx0/pCkVU9RU33RqexQIagAYocXTF0cazIMxRw0AgSOoA5Tr5vlCqwModkx9BKa/eb6/L7O/eV5STg+tQq0DACPq4OSjeb6Q6ggJRxip2B/5w4g6MPloni+kOkLBEUYq9kd+MaIOTD6a5wupDimMkRtHGKnYH/lFUAcmH83zhVRHPi54kwmOMFKxP/KLoA7M4umLtfbqtbqg4gKZTBdUXKC1V6/N++FkKHWEMnIL6QgjBOyP/GKOOkC5bp4vpDpCGbk11TelzMlK8RxhhIL9kV8ENYI2pWKKOo53pN2eT/k4TbiQsD/yy9w98hdNJBLe2toa+eui+AzuLpCSI7c4pmGAXDKz7e6eSPcYI2oEjZEbEFBQtxxo4cOItEKYKwfiFERQ0zwPAEMLoj0vlBYsAAhREEEdSgsWAIQoiKCmeR7IXAin1CO/ggjqUE5XlvgQIGyhnFKP/AoiqEM5XZkPAULHek5xCqLrQwqjBetMH4K4awMk1nOKVRAj6lDwIUDoWM8pTsMGtZmVmdl/m9nLZrbbzO7KR2Fx4EOA0IW0noP8yWRE/X+SrnX3uZKukHS9mc3PaVUx4UOA0IWynoP8GnaO2pNXbXq/78fSvv9FfyWnAHBdCRSCENZzkF8ZLSaaWYmk7ZIukfQjd38hp1XFiA8BgNBktJjo7r3ufoWkaklXmdnswc8xs2Vm1mpmrZ2dnRGXCQDFK6uuD3c/Kul3kq5P89gGd0+4e6Kqqiqi8gAAmXR9VJlZZd/35ZI+KWlfjusCAPTJZI76AkkP9M1Tj5G0yd1/k9uyAAD9Mun62CVpXh5qAQCkwZmJABA4ghoAAkdQA0DgCGoACBxBDQCBI6gBIHAENQAEjqAGgMAR1AAKVrHcjDqYeyYCQDb6b0bdf5/T/ptRSxp1lypmRA2gIBXTHdkJagAFqZhuRk1QAyhIxXQzaoIaQEEqpptRs5gIoCAV082oCWoABatYbkbN1AcABI6gBoDAEdQAEDiCGgACR1ADQODM3aN/UbNOSX85y1+fJOntCMspZOyLVOyPVOyP00bDvrjY3avSPZCToB4JM2t190TcdYSAfZGK/ZGK/XHaaN8XTH0AQOAIagAIXIhBvSHuAgLCvkjF/kjF/jhtVO+L4OaoAQCpQhxRAwAGIKgBIHDBBLWZXW9m+83sT2b2zbjriZOZXWhmvzOzPWa228xG3wV2s2RmJWa208x+E3ctcTOzSjPbbGb7zGyvmX0s7priZGYr+z4nr5rZw2ZWNvxvFZYggtrMSiT9SNKnJF0uaamZXR5vVbE6Kemf3f1ySfMlLS/y/SFJTZL2xl1EINZLesLdZ0qaqyLeL2Y2TdIKSQl3ny2pRNIt8VYVvSCCWtJVkv7k7gfc/YSkX0n6bMw1xcbdO9x9R9/3f1Pygzgt3qriY2bVkhZLui/uWuJmZuMlNUj6mSS5+wl3PxprUfE7R1K5mZ0j6XxJb8VcT+RCCeppkt4c8HObijiYBjKzGknzJL0QcylxulfSNyR9EHMdIaiV1Cnp531TQfeZWUXcRcXF3dslrZP0hqQOScfc/al4q4peKEGNNMxsrKRHJP2Tu78Xdz1xMLMbJP3V3bfHXUsgzpFUL+kn7j5P0nFJRbumY2YTlDz6rpU0VVKFmX0h3qqiF0pQt0u6cMDP1X3bipaZlSoZ0g+6e3Pc9cRogaTPmNlBJafErjWzX8ZbUqzaJLW5e/8R1mYlg7tYfULS6+7e6e49kpolXR1zTZELJahflHSpmdWa2blKLgY8FnNNsTEzU3IOcq+7fz/ueuLk7ne6e7W71yj5d/GMu4+6EVOm3P2QpDfNbEbfpkWS9sRYUtzekDTfzM7v+9ws0ihcXA3i5rbuftLM/lHSk0qu2t7v7rtjLitOCyT9g6RXzOylvm3/4u6Px1cSAvJ1SQ/2DWoOSPpSzPXExt1fMLPNknYo2S21U6PwdHJOIQeAwIUy9QEAGAJBDQCBI6gBIHAENQAEjqAGgMAR1AAQOIIaAAL3/4sVqVScauxuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(len(high_se)), high_se[cluster])\n",
    "plt.scatter(range(len(rand_se)), rand_se[cluster])\n",
    "plt.scatter(range(len(low_se)), low_se[cluster])\n",
    "plt.legend(['high', 'rand', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand mean:  5.470405970535876 rand std:  0.0\n",
      "high mean:  7.540590931140479 high std:  0.0\n",
      "low mean:  3.2464544830797135 low std:  0.0\n",
      "rand vs high:  1.0\n",
      "rand vs low:  1.0\n",
      "high vs low:  1.0\n"
     ]
    }
   ],
   "source": [
    "summary(rand_se[cluster], high_se[cluster], low_se[cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pheno in plist:\n",
    "#     result = pheno_result[pheno]\n",
    "#     rand_se = result['rand']\n",
    "#     high_se = result['high']\n",
    "#     low_se = result['low']\n",
    "#     summary(rand_se, high_se, low_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_S1-C1</th>\n",
       "      <th>cluster_S1-C2</th>\n",
       "      <th>cluster_S1-C3</th>\n",
       "      <th>cluster_S1-C4</th>\n",
       "      <th>cluster_S1-C5</th>\n",
       "      <th>cluster_S1-C6</th>\n",
       "      <th>cluster_S1-C7</th>\n",
       "      <th>cluster_S1-C8</th>\n",
       "      <th>cluster_S1-C9</th>\n",
       "      <th>cluster_S1-C10</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_C7</th>\n",
       "      <th>cluster_C8</th>\n",
       "      <th>cluster_C9</th>\n",
       "      <th>cluster_C10</th>\n",
       "      <th>supercluster_S1</th>\n",
       "      <th>supercluster_S2</th>\n",
       "      <th>supercluster_S3</th>\n",
       "      <th>supercluster_S4</th>\n",
       "      <th>supercluster_S5</th>\n",
       "      <th>supercluster_S6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAMD00164938</th>\n",
       "      <td>0.253652</td>\n",
       "      <td>0.246818</td>\n",
       "      <td>0.280356</td>\n",
       "      <td>0.159395</td>\n",
       "      <td>0.352237</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.340951</td>\n",
       "      <td>0.122817</td>\n",
       "      <td>0.266321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195731</td>\n",
       "      <td>0.235521</td>\n",
       "      <td>0.033014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.246454</td>\n",
       "      <td>1.171356</td>\n",
       "      <td>1.444991</td>\n",
       "      <td>0.223082</td>\n",
       "      <td>0.181365</td>\n",
       "      <td>0.855927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cluster_S1-C1  cluster_S1-C2  cluster_S1-C3  cluster_S1-C4  \\\n",
       "SAMD00164938       0.253652       0.246818       0.280356       0.159395   \n",
       "\n",
       "              cluster_S1-C5  cluster_S1-C6  cluster_S1-C7  cluster_S1-C8  \\\n",
       "SAMD00164938       0.352237       0.006709       0.008955       0.340951   \n",
       "\n",
       "              cluster_S1-C9  cluster_S1-C10  ...  cluster_C7  cluster_C8  \\\n",
       "SAMD00164938       0.122817        0.266321  ...    0.195731    0.235521   \n",
       "\n",
       "              cluster_C9  cluster_C10  supercluster_S1  supercluster_S2  \\\n",
       "SAMD00164938    0.033014          0.0         3.246454         1.171356   \n",
       "\n",
       "              supercluster_S3  supercluster_S4  supercluster_S5  \\\n",
       "SAMD00164938         1.444991         0.223082         0.181365   \n",
       "\n",
       "              supercluster_S6  \n",
       "SAMD00164938         0.855927  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SAMD00164938'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
