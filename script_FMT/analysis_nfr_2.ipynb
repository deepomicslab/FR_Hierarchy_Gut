{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for mutiple regression on nFR, days after FMT and fraction at each cluster/super-cluster.\n",
    "# FMT dataset 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import tree_util\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frac_df = pd.read_csv('../data/FMT/FMT2/Eric.txt', sep='\\t', header=0, index_col=0)\n",
    "deltat = pd.read_csv('../data/FMT/FMT2/deltat.txt', sep='\\t', header=0, index_col=0)\n",
    "triads = pd.read_csv('../data/FMT/FMT2/triads.txt', sep='\\t', header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in triads.index:\n",
    "    posts = triads.loc[idx, 'post_samples'].strip().split(',')\n",
    "    times = []\n",
    "    for p in posts:\n",
    "        if p not in deltat.index:\n",
    "            print(p)\n",
    "        else:\n",
    "            times.append(str(deltat.loc[p, 'delta_t']))\n",
    "    t_str = ','.join(times)\n",
    "    triads.loc[idx, 'days'] = t_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in frac_df.index:\n",
    "    d = frac_df.loc[idx, 'Days postFMT']\n",
    "    cand = triads[triads['days'] == d]['pre_sample']\n",
    "    ids = triads[triads['days'] == d].index\n",
    "    if len(cand) == 1:\n",
    "        #print(list(cand))\n",
    "        s = list(cand)[0]\n",
    "        frac_df.loc[idx, 'sname'] = s\n",
    "        triads.loc[list(ids)[0], 'alias'] = idx\n",
    "triads.loc[10, 'alias'] = 'FMT5' \n",
    "s = triads.loc[10, 'pre_sample']\n",
    "frac_df.loc['FMT5', 'sname'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nFR for a sample\n",
    "def nfr_value(d_df, profile, sname):\n",
    "    sp_list = list(profile.columns)\n",
    "    n = len(sp_list)\n",
    "    corr = np.ones(shape=(n, n)) - d_df.loc[sp_list, sp_list].values\n",
    "    np.fill_diagonal(corr, 0)\n",
    "    # print(corr[1, 1])\n",
    "    a = np.array(profile.loc[sname, sp_list])\n",
    "    inter_matrix = np.dot(a.reshape(len(a), 1),a.reshape(1, len(a)))\n",
    "    np.fill_diagonal(inter_matrix, 0)\n",
    "    td = np.sum(inter_matrix)/2\n",
    "    fr = np.sum(np.multiply(inter_matrix, corr))/2\n",
    "    fd = np.sum(np.multiply(inter_matrix, d_df.loc[sp_list, sp_list].values))/2\n",
    "    if td == 0:\n",
    "        return 0\n",
    "    return fr/td\n",
    "\n",
    "# compute nFR for all sample\n",
    "def multisample_nfr(profile, d_df, node_leaves):\n",
    "    result = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    for sname in profile.index:\n",
    "       for node, sp_list in node_leaves.items():\n",
    "           sp_list = list(set(sp_list).intersection(set(profile.columns)))\n",
    "           selected_d = d_df.loc[sp_list, sp_list]\n",
    "           selected_profile = profile.loc[:, sp_list]\n",
    "           value = nfr_value(selected_d, selected_profile, sname)\n",
    "           result.loc[sname, node] = value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tree\n",
    "with open('../result/GCN_fix_tree/renamed_GCN_tree.newick') as fp:\n",
    "    newick_tree = fp.read()\n",
    "    # newick_tree = newick_tree.replace('-', '_')\n",
    "    \n",
    "# construct tree with newick string\n",
    "json_tree = tree_util.parse(newick_tree)\n",
    "largest = {'largest': 0}\n",
    "leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "largest_level = largest['largest']\n",
    "nlayer = largest_level\n",
    "layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "\n",
    "tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "leaves_dict = copy.deepcopy(layer_leaves_dict)\n",
    "\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "node_leaves = {}\n",
    "for level in layer_leaves_dict.keys():\n",
    "    for node, sp_list in layer_leaves_dict[level].items():\n",
    "        if node in node_leaves.keys():\n",
    "            continue\n",
    "        node_leaves[node] = copy.deepcopy(sp_list)\n",
    "subtree_nodes = {}\n",
    "for l in leaf_list:\n",
    "    parent = parent_dict[l]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent].append(l)\n",
    "\n",
    "for node in node_leaves.keys():\n",
    "    parent = parent_dict[node]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent] += subtree_nodes[node]\n",
    "    subtree_nodes[parent].append(node)\n",
    "\n",
    "for node in subtree_nodes.keys():\n",
    "    subtree_nodes[node].append(node)\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)\n",
    "\n",
    "node_leaves['root'] = copy.deepcopy(leaf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance, abundance profile and metadata\n",
    "outdir = '../result/FMT/nFR/FMT2'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "param = 0.5\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "abd = pd.read_csv('../data/FMT/FMT2/Eric_abd.tsv', sep='\\t', header=0, index_col=0)\n",
    "name_dict = {}\n",
    "for sp in d_df.columns:\n",
    "        name_dict[sp] = sp.replace('_', '-')\n",
    "d_df = d_df.rename(columns=name_dict, index=name_dict)\n",
    "abd = abd.rename(columns=name_dict)\n",
    "profile = abd[list(set(abd.columns).intersection(set(d_df.columns)))]\n",
    "profile = profile.div(profile.sum(axis=1), axis=0)\n",
    "\n",
    "profile = profile.rename(index={'FMT5':'FMT05'})\n",
    "pre_slist = list(frac_df['sname'])\n",
    "profile = profile.loc[pre_slist,]\n",
    "rename_dict = {}\n",
    "for idx in frac_df.index:\n",
    "    rename_dict[frac_df.loc[idx, 'sname']] = idx\n",
    "profile.rename(index=rename_dict).to_csv(os.path.join(outdir, 'abd.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nFR for all samples at timepoint 0\n",
    "nfr_df = multisample_nfr(profile, d_df, node_leaves)\n",
    "nfr_df = nfr_df.T\n",
    "nfr_df = nfr_df.drop('nroot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cutoff = 0.05\n",
    "# prepare frac and t for regression\n",
    "frac = []\n",
    "t = []\n",
    "sname_list = []\n",
    "for idx in frac_df.index:\n",
    "    sname = frac_df.loc[idx, 'sname']\n",
    "    t_str = frac_df.loc[idx, 'Days postFMT']\n",
    "    frac_str = frac_df.loc[idx, 'Fraction of donor specific strains']\n",
    "    t += [int(ts) for ts in t_str.split(',')]\n",
    "    frac += [float(f) for f in frac_str.split(',')]\n",
    "    sname_list += [sname]*len(t_str.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "odf = pd.DataFrame(columns=['F-pvalue', 'nfr_co', 't_co', 'const_co', 'nfr_p', 't_p', 'const_p'])\n",
    "for node in node_leaves.keys():\n",
    "    nfr = []\n",
    "    for sname in sname_list:\n",
    "        value = nfr_df.loc[node, sname]\n",
    "        nfr.append(value)\n",
    "    if sum(nfr) == 0:\n",
    "        continue\n",
    "    df = pd.DataFrame()\n",
    "    df['frac'] = frac\n",
    "    df['nfr'] = nfr\n",
    "    df['t'] = t\n",
    "\n",
    "    X = df[['nfr', 't']]\n",
    "    y = df['frac']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    odf.loc[node, 'F-pvalue'] = result.f_pvalue\n",
    "    for var in result.pvalues.index:\n",
    "        odf.loc[node, \"{}_co\".format(var)] = result.params[var]\n",
    "        odf.loc[node, \"{}_p\".format(var)] = result.pvalues[var]\n",
    "odf.sort_values(by='F-pvalue').to_csv(os.path.join(outdir, 'p_values.tsv'), index=True, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-pvalue</th>\n",
       "      <th>nfr_co</th>\n",
       "      <th>t_co</th>\n",
       "      <th>const_co</th>\n",
       "      <th>nfr_p</th>\n",
       "      <th>t_p</th>\n",
       "      <th>const_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C3</th>\n",
       "      <td>0.015189</td>\n",
       "      <td>-0.442987</td>\n",
       "      <td>0.000550979</td>\n",
       "      <td>0.653932</td>\n",
       "      <td>0.0040558</td>\n",
       "      <td>0.57552</td>\n",
       "      <td>1.56364e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C4</th>\n",
       "      <td>0.00413328</td>\n",
       "      <td>1.0492</td>\n",
       "      <td>0.000521183</td>\n",
       "      <td>-0.0943784</td>\n",
       "      <td>0.00099963</td>\n",
       "      <td>0.581792</td>\n",
       "      <td>0.55523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C5</th>\n",
       "      <td>0.0252543</td>\n",
       "      <td>-0.535224</td>\n",
       "      <td>0.000609198</td>\n",
       "      <td>0.760055</td>\n",
       "      <td>0.0070705</td>\n",
       "      <td>0.543664</td>\n",
       "      <td>6.7932e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C10</th>\n",
       "      <td>0.0140769</td>\n",
       "      <td>-0.470651</td>\n",
       "      <td>-9.36477e-05</td>\n",
       "      <td>0.516373</td>\n",
       "      <td>0.00373415</td>\n",
       "      <td>0.923037</td>\n",
       "      <td>1.93443e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C15</th>\n",
       "      <td>0.00198524</td>\n",
       "      <td>-0.402447</td>\n",
       "      <td>0.00107787</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.000458754</td>\n",
       "      <td>0.26274</td>\n",
       "      <td>2.12027e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S2-C5</th>\n",
       "      <td>0.0323182</td>\n",
       "      <td>-0.581848</td>\n",
       "      <td>0.00023281</td>\n",
       "      <td>0.787635</td>\n",
       "      <td>0.00928013</td>\n",
       "      <td>0.814373</td>\n",
       "      <td>3.18566e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_C7</th>\n",
       "      <td>0.0442497</td>\n",
       "      <td>-0.296316</td>\n",
       "      <td>-1.8189e-05</td>\n",
       "      <td>0.507224</td>\n",
       "      <td>0.0131572</td>\n",
       "      <td>0.98547</td>\n",
       "      <td>7.0465e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supercluster_S1</th>\n",
       "      <td>0.000268792</td>\n",
       "      <td>1.86365</td>\n",
       "      <td>-0.00045584</td>\n",
       "      <td>-0.289235</td>\n",
       "      <td>5.62406e-05</td>\n",
       "      <td>0.604101</td>\n",
       "      <td>0.0925307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F-pvalue    nfr_co         t_co   const_co        nfr_p  \\\n",
       "cluster_S1-C3       0.015189 -0.442987  0.000550979   0.653932    0.0040558   \n",
       "cluster_S1-C4     0.00413328    1.0492  0.000521183 -0.0943784   0.00099963   \n",
       "cluster_S1-C5      0.0252543 -0.535224  0.000609198   0.760055    0.0070705   \n",
       "cluster_S1-C10     0.0140769 -0.470651 -9.36477e-05   0.516373   0.00373415   \n",
       "cluster_S1-C15    0.00198524 -0.402447   0.00107787   0.577465  0.000458754   \n",
       "cluster_S2-C5      0.0323182 -0.581848   0.00023281   0.787635   0.00928013   \n",
       "cluster_C7         0.0442497 -0.296316  -1.8189e-05   0.507224    0.0131572   \n",
       "supercluster_S1  0.000268792   1.86365  -0.00045584  -0.289235  5.62406e-05   \n",
       "\n",
       "                      t_p      const_p  \n",
       "cluster_S1-C3     0.57552  1.56364e-10  \n",
       "cluster_S1-C4    0.581792      0.55523  \n",
       "cluster_S1-C5    0.543664   6.7932e-08  \n",
       "cluster_S1-C10   0.923037  1.93443e-14  \n",
       "cluster_S1-C15    0.26274  2.12027e-14  \n",
       "cluster_S2-C5    0.814373  3.18566e-07  \n",
       "cluster_C7        0.98547   7.0465e-14  \n",
       "supercluster_S1  0.604101    0.0925307  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf[odf['F-pvalue']<p_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regression results\n",
    "formula_tmp = r'$f_{{ds}} = {:.4f}*nFR_{{pre}} + {:.4f}*t_{{post}} + {:.4f}$' + '\\np = {:.4}'\n",
    "\n",
    "for node in sorted(list(odf.index)):\n",
    "    nfr_co = odf.loc[node, 'nfr_co']\n",
    "    t_co = odf.loc[node, 't_co']\n",
    "    const = odf.loc[node, 'const_co']\n",
    "    p_value = odf.loc[node, 'F-pvalue']\n",
    "    nfr = np.linspace(0, max(max(nfr_df.loc[node, ])*1.1, 0.05), 1000)\n",
    "    t = np.linspace(0, 150, 1000)\n",
    "    X, Y = np.meshgrid(nfr, t)\n",
    "    f = nfr_co*X + t_co*Y + const\n",
    "    f[f>1] = np.nan\n",
    "    f[f<0] = np.nan\n",
    "    formula = formula_tmp.format(nfr_co, t_co, const, p_value)\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    cmp = plt.cm.YlGnBu_r\n",
    "    surf = ax.plot_surface(X, Y, f, cmap=cmp, alpha=0.5)\n",
    "    surf.set_clim(0, 1)\n",
    "    ax.set_yticks(np.arange(0, 150, 50))\n",
    "    ax.set_yticklabels(np.arange(0, 150, 50))\n",
    "\n",
    "    ax.set_zlim((0, 1))\n",
    "    ax.set_zticks(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "    ax.set_zticklabels(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "\n",
    "    ax.set_xlabel(r'$nFR_{pre}$', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel(r'$t_{post}$', fontweight='bold', fontsize=14)\n",
    "    ax.zaxis.set_rotate_label(False) \n",
    "    ax.set_zlabel(r'$f_{ds}$', fontweight='bold', fontsize=14)\n",
    "\n",
    "    nfr = []\n",
    "    frac = []\n",
    "    t = []\n",
    "    colors = []\n",
    "    slist = []\n",
    "    for sname in frac_df.index:\n",
    "        sname2 = frac_df.loc[sname, 'sname']\n",
    "        t_str = frac_df.loc[sname, 'Days postFMT']\n",
    "        frac_str = frac_df.loc[sname, 'Fraction of donor specific strains']\n",
    "        n_t = len(t_str.split(','))\n",
    "        t += [int(ts) for ts in t_str.split(',')]\n",
    "        frac += [float(f) for f in frac_str.split(',')]\n",
    "        #c += [color_dict[int(sname[3:])]] * n_t\n",
    "        colors += [int(sname[3:])-1] * n_t\n",
    "        nfr += [nfr_df.loc[node, sname2]] * n_t\n",
    "        slist += [sname] * n_t\n",
    "\n",
    "    point_df = pd.DataFrame(columns=['sample', 'nFR_pre', 't_post', 'f_ds'])\n",
    "    point_df['sample'] = slist\n",
    "    point_df['nFR_pre'] = nfr\n",
    "    point_df['t_post'] = t\n",
    "    point_df['f_ds'] = frac\n",
    "\n",
    "    point_df.to_csv(os.path.join(outdir, '{}.tsv'.format(node)), sep='\\t', header=True, index=False)\n",
    "\n",
    "    ax.scatter(nfr, t, frac, c = colors, cmap='tab20')\n",
    "    ax.view_init(elev=15, azim=245)\n",
    "    ax.set_title(formula, y = 0.95)\n",
    "    ax.xaxis.set_pane_color((1, 1, 1, 1))\n",
    "    ax.yaxis.set_pane_color((1, 1, 1, 1))\n",
    "    ax.zaxis.set_pane_color((1, 1, 1, 1))\n",
    "    plt.suptitle(node.replace('_', ' '))\n",
    "    # fig.colorbar(surf)\n",
    "    plt.tight_layout()\n",
    "    opath = os.path.join(outdir, '{}.pdf'.format(node))\n",
    "    plt.savefig(opath, dpi=300, format='pdf')\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
