{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is for mutiple regression on SE, days after FMT and fraction at each cluster/super-cluster.\n",
    "\n",
    "FMT dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for mutiple regression on SE, days after FMT and fraction at each cluster/super-cluster.\n",
    "# FMT dataset 2\n",
    "import sys\n",
    "sys.path.append('../frstruct')\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import tree_util\n",
    "import se\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frac_df = pd.read_csv('../data/FMT/FMT2/Eric.txt', sep='\\t', header=0, index_col=0)\n",
    "deltat = pd.read_csv('../data/FMT/FMT2/deltat.txt', sep='\\t', header=0, index_col=0)\n",
    "triads = pd.read_csv('../data/FMT/FMT2/triads.txt', sep='\\t', header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in triads.index:\n",
    "    posts = triads.loc[idx, 'post_samples'].strip().split(',')\n",
    "    times = []\n",
    "    for p in posts:\n",
    "        if p not in deltat.index:\n",
    "            print(p)\n",
    "        else:\n",
    "            times.append(str(deltat.loc[p, 'delta_t']))\n",
    "    t_str = ','.join(times)\n",
    "    triads.loc[idx, 'days'] = t_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in frac_df.index:\n",
    "    d = frac_df.loc[idx, 'Days postFMT']\n",
    "    cand = triads[triads['days'] == d]['pre_sample']\n",
    "    ids = triads[triads['days'] == d].index\n",
    "    if len(cand) == 1:\n",
    "        #print(list(cand))\n",
    "        s = list(cand)[0]\n",
    "        frac_df.loc[idx, 'sname'] = s\n",
    "        triads.loc[list(ids)[0], 'alias'] = idx\n",
    "triads.loc[10, 'alias'] = 'FMT5' \n",
    "s = triads.loc[10, 'pre_sample']\n",
    "frac_df.loc['FMT5', 'sname'] = s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR networkfor a sample\n",
    "def fr(d_df, profile, sname):\n",
    "    sp_list = list(profile.columns)\n",
    "    sp_d_df = d_df.loc[sp_list, sp_list]\n",
    "    #print(profile)\n",
    "    sp_profile = np.array(profile.loc[sname, sp_list])\n",
    "    value = np.dot(sp_profile.reshape(len(sp_profile), 1),sp_profile.reshape(1, len(sp_profile)))\n",
    "    width = value.shape[0]\n",
    "    cor_df = np.ones(shape=(width, width)) - sp_d_df.values\n",
    "    for i in range(width):\n",
    "        cor_df[i][i] = 0\n",
    "    value = np.multiply(value, cor_df)\n",
    "    df = pd.DataFrame(data= value, index=sp_list, columns=sp_list)\n",
    "    return df\n",
    "\n",
    "# compute SE for all samples\n",
    "def multisample_se(profile, d_df, parent_dict, node_leaves, child_dict, direct_children_dict, param):\n",
    "    result = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    for sname in profile.index:\n",
    "       # print(sname)\n",
    "       edge_df = fr(d_df, profile, sname)\n",
    "       tmp = se.subtree_se_adj(edge_df, parent_dict, node_leaves, child_dict, direct_children_dict, param)\n",
    "       for node in tmp.keys():\n",
    "           value = tmp[node]\n",
    "           result.loc[sname, node] = value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tree\n",
    "with open('../result/GCN_fix_tree/renamed_GCN_tree.newick') as fp:\n",
    "    newick_tree = fp.read()\n",
    "    # newick_tree = newick_tree.replace('-', '_')\n",
    "    \n",
    "# construct tree with newick string\n",
    "json_tree = tree_util.parse(newick_tree)\n",
    "largest = {'largest': 0}\n",
    "leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "largest_level = largest['largest']\n",
    "nlayer = largest_level\n",
    "layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "\n",
    "tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "leaves_dict = copy.deepcopy(layer_leaves_dict)\n",
    "\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "node_leaves = {}\n",
    "for level in layer_leaves_dict.keys():\n",
    "    for node, sp_list in layer_leaves_dict[level].items():\n",
    "        if node in node_leaves.keys():\n",
    "            continue\n",
    "        node_leaves[node] = copy.deepcopy(sp_list)\n",
    "subtree_nodes = {}\n",
    "for l in leaf_list:\n",
    "    parent = parent_dict[l]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent].append(l)\n",
    "\n",
    "for node in node_leaves.keys():\n",
    "    parent = parent_dict[node]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent] += subtree_nodes[node]\n",
    "    subtree_nodes[parent].append(node)\n",
    "\n",
    "for node in subtree_nodes.keys():\n",
    "    subtree_nodes[node].append(node)\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)\n",
    "\n",
    "node_leaves['root'] = copy.deepcopy(leaf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance, abundance profile and metadata\n",
    "outdir = '../result/FMT/SE/FMT2'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "param = 0.5\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "abd = pd.read_csv('../data/FMT/FMT2/Eric_abd.tsv', sep='\\t', header=0, index_col=0)\n",
    "name_dict = {}\n",
    "for sp in d_df.columns:\n",
    "        name_dict[sp] = sp.replace('_', '-')\n",
    "d_df = d_df.rename(columns=name_dict, index=name_dict)\n",
    "abd = abd.rename(columns=name_dict)\n",
    "profile = abd[list(set(abd.columns).intersection(set(d_df.columns)))]\n",
    "profile = profile.div(profile.sum(axis=1), axis=0)\n",
    "\n",
    "profile = profile.rename(index={'FMT5':'FMT05'})\n",
    "pre_slist = list(frac_df['sname'])\n",
    "profile = profile.loc[pre_slist,]\n",
    "rename_dict = {}\n",
    "for idx in frac_df.index:\n",
    "    rename_dict[frac_df.loc[idx, 'sname']] = idx\n",
    "profile.rename(index=rename_dict).to_csv(os.path.join(outdir, 'abd.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SE for all samples at timepoint 0\n",
    "se_df = multisample_se(profile, d_df, parent_dict, node_leaves, subtree_nodes, direct_children_dict, param)\n",
    "se_df = se_df.T\n",
    "se_df = se_df.drop('nroot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cutoff = 0.05\n",
    "# prepare frac and t for regression\n",
    "frac = []\n",
    "t = []\n",
    "sname_list = []\n",
    "for idx in frac_df.index:\n",
    "    sname = frac_df.loc[idx, 'sname']\n",
    "    t_str = frac_df.loc[idx, 'Days postFMT']\n",
    "    frac_str = frac_df.loc[idx, 'Fraction of donor specific strains']\n",
    "    t += [int(ts) for ts in t_str.split(',')]\n",
    "    frac += [float(f) for f in frac_str.split(',')]\n",
    "    sname_list += [sname]*len(t_str.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "odf = pd.DataFrame(columns=['F-pvalue', 'se_co', 't_co', 'const_co', 'se_p', 't_p', 'const_p'])\n",
    "for node in node_leaves.keys():\n",
    "    se = []\n",
    "    for sname in sname_list:\n",
    "        value = se_df.loc[node, sname]\n",
    "        se.append(value)\n",
    "    if sum(se) == 0:\n",
    "        continue\n",
    "    df = pd.DataFrame()\n",
    "    df['frac'] = frac\n",
    "    df['se'] = se\n",
    "    df['t'] = t\n",
    "\n",
    "    X = df[['se', 't']]\n",
    "    y = df['frac']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    odf.loc[node, 'F-pvalue'] = result.f_pvalue\n",
    "    for var in result.pvalues.index:\n",
    "        odf.loc[node, \"{}_co\".format(var)] = result.params[var]\n",
    "        odf.loc[node, \"{}_p\".format(var)] = result.pvalues[var]\n",
    "odf.sort_values(by='F-pvalue').to_csv(os.path.join(outdir, 'p_values.tsv'), index=True, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-pvalue</th>\n",
       "      <th>se_co</th>\n",
       "      <th>t_co</th>\n",
       "      <th>const_co</th>\n",
       "      <th>se_p</th>\n",
       "      <th>t_p</th>\n",
       "      <th>const_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C1</th>\n",
       "      <td>0.030192</td>\n",
       "      <td>-0.139042</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.525113</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>0.932526</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C2</th>\n",
       "      <td>0.026418</td>\n",
       "      <td>-0.646164</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>0.544587</td>\n",
       "      <td>0.00743</td>\n",
       "      <td>0.890594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C3</th>\n",
       "      <td>0.003328</td>\n",
       "      <td>-0.946179</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>0.514195</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.706879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_S1-C15</th>\n",
       "      <td>0.019309</td>\n",
       "      <td>-1.448979</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.515091</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.72297</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                F-pvalue     se_co      t_co  const_co      se_p       t_p  \\\n",
       "cluster_S1-C1   0.030192 -0.139042  0.000084  0.525113  0.008608  0.932526   \n",
       "cluster_S1-C2   0.026418 -0.646164 -0.000136  0.544587   0.00743  0.890594   \n",
       "cluster_S1-C3   0.003328 -0.946179 -0.000353  0.514195  0.000794  0.706879   \n",
       "cluster_S1-C15  0.019309 -1.448979  -0.00035  0.515091  0.005268   0.72297   \n",
       "\n",
       "               const_p  \n",
       "cluster_S1-C1      0.0  \n",
       "cluster_S1-C2      0.0  \n",
       "cluster_S1-C3      0.0  \n",
       "cluster_S1-C15     0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf[odf['F-pvalue']<p_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regression results\n",
    "formula_tmp = r'$f_{{ds}} = {:.4f}*SE_{{pre}} + {:.4f}*t_{{post}} + {:.4f}$' + '\\np = {:.4}'\n",
    "\n",
    "for node in sorted(list(odf.index)):\n",
    "    se_co = odf.loc[node, 'se_co']\n",
    "    t_co = odf.loc[node, 't_co']\n",
    "    const = odf.loc[node, 'const_co']\n",
    "    p_value = odf.loc[node, 'F-pvalue']\n",
    "    se = np.linspace(0, max(max(se_df.loc[node, ])*1.1, 0.05), 1000)\n",
    "    t = np.linspace(0, 150, 1000)\n",
    "    X, Y = np.meshgrid(se, t)\n",
    "    f = se_co*X + t_co*Y + const\n",
    "    f[f>1] = np.nan\n",
    "    f[f<0] = np.nan\n",
    "    formula = formula_tmp.format(se_co, t_co, const, p_value)\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    cmp = plt.cm.YlGnBu_r\n",
    "    surf = ax.plot_surface(X, Y, f, cmap=cmp, alpha=0.5)\n",
    "    surf.set_clim(0, 1)\n",
    "    ax.set_yticks(np.arange(0, 150, 50))\n",
    "    ax.set_yticklabels(np.arange(0, 150, 50))\n",
    "\n",
    "    ax.set_zlim((0, 1))\n",
    "    ax.set_zticks(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "    ax.set_zticklabels(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "\n",
    "    ax.set_xlabel(r'$SE_{pre}$', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel(r'$t_{post}$', fontweight='bold', fontsize=14)\n",
    "    ax.zaxis.set_rotate_label(False) \n",
    "    ax.set_zlabel(r'$f_{ds}$', fontweight='bold', fontsize=14)\n",
    "\n",
    "    se = []\n",
    "    frac = []\n",
    "    t = []\n",
    "    colors = []\n",
    "    slist = []\n",
    "    for sname in frac_df.index:\n",
    "        sname2 = frac_df.loc[sname, 'sname']\n",
    "        t_str = frac_df.loc[sname, 'Days postFMT']\n",
    "        frac_str = frac_df.loc[sname, 'Fraction of donor specific strains']\n",
    "        n_t = len(t_str.split(','))\n",
    "        t += [int(ts) for ts in t_str.split(',')]\n",
    "        frac += [float(f) for f in frac_str.split(',')]\n",
    "        #c += [color_dict[int(sname[3:])]] * n_t\n",
    "        colors += [int(sname[3:])-1] * n_t\n",
    "        se += [se_df.loc[node, sname2]] * n_t\n",
    "        slist += [sname] * n_t\n",
    "\n",
    "    point_df = pd.DataFrame(columns=['sample', 'SE_pre', 't_post', 'f_ds'])\n",
    "    point_df['sample'] = slist\n",
    "    point_df['SE_pre'] = se\n",
    "    point_df['t_post'] = t\n",
    "    point_df['f_ds'] = frac\n",
    "\n",
    "    point_df.to_csv(os.path.join(outdir, '{}.tsv'.format(node)), sep='\\t', header=True, index=False)\n",
    "\n",
    "    ax.scatter(se, t, frac, c = colors, cmap='tab20')\n",
    "    ax.view_init(elev=15, azim=245)\n",
    "    ax.set_title(formula, y = 0.95)\n",
    "    ax.xaxis.set_pane_color((1, 1, 1, 1))\n",
    "    ax.yaxis.set_pane_color((1, 1, 1, 1))\n",
    "    ax.zaxis.set_pane_color((1, 1, 1, 1))\n",
    "    plt.suptitle(node.replace('_', ' '))\n",
    "    # fig.colorbar(surf)\n",
    "    plt.tight_layout()\n",
    "    opath = os.path.join(outdir, '{}.pdf'.format(node))\n",
    "    plt.savefig(opath, dpi=300, format='pdf')\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr_r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
