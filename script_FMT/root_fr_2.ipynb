{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is for mutiple regression on td/fd/fr, days after FMT and fraction at root.\n",
    "\n",
    "FMT dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for mutiple regression on td/fd/fr, days after FMT and fraction at root.\n",
    "# FMT dataset 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import tree_util\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frac_df = pd.read_csv('../data/FMT/FMT2/Eric.txt', sep='\\t', header=0, index_col=0)\n",
    "deltat = pd.read_csv('../data/FMT/FMT2/deltat.txt', sep='\\t', header=0, index_col=0)\n",
    "triads = pd.read_csv('../data/FMT/FMT2/triads.txt', sep='\\t', header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in triads.index:\n",
    "    posts = triads.loc[idx, 'post_samples'].strip().split(',')\n",
    "    times = []\n",
    "    for p in posts:\n",
    "        if p not in deltat.index:\n",
    "            print(p)\n",
    "        else:\n",
    "            times.append(str(deltat.loc[p, 'delta_t']))\n",
    "    t_str = ','.join(times)\n",
    "    triads.loc[idx, 'days'] = t_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in frac_df.index:\n",
    "    d = frac_df.loc[idx, 'Days postFMT']\n",
    "    cand = triads[triads['days'] == d]['pre_sample']\n",
    "    ids = triads[triads['days'] == d].index\n",
    "    if len(cand) == 1:\n",
    "        #print(list(cand))\n",
    "        s = list(cand)[0]\n",
    "        frac_df.loc[idx, 'sname'] = s\n",
    "        triads.loc[list(ids)[0], 'alias'] = idx\n",
    "triads.loc[10, 'alias'] = 'FMT5' \n",
    "s = triads.loc[10, 'pre_sample']\n",
    "frac_df.loc['FMT5', 'sname'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR,td,fd for a sample\n",
    "def fr_value(d_df, profile, sname):\n",
    "    sp_list = list(profile.columns)\n",
    "    n = len(sp_list)\n",
    "    corr = np.ones(shape=(n, n)) - d_df.loc[sp_list, sp_list].values\n",
    "    np.fill_diagonal(corr, 0)\n",
    "    # print(corr[1, 1])\n",
    "    a = np.array(profile.loc[sname, sp_list])\n",
    "    inter_matrix = np.dot(a.reshape(len(a), 1),a.reshape(1, len(a)))\n",
    "    np.fill_diagonal(inter_matrix, 0)\n",
    "    td = np.sum(inter_matrix)/2\n",
    "    fr = np.sum(np.multiply(inter_matrix, corr))/2\n",
    "    fd = np.sum(np.multiply(inter_matrix, d_df.loc[sp_list, sp_list].values))/2\n",
    "    if td == 0:\n",
    "        return 0\n",
    "    return fr, td, fd\n",
    "\n",
    "# compute FR, td, fd for all sample\n",
    "def multisample_fr(profile, d_df, node_leaves):\n",
    "    result = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    result2 = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    result3 = pd.DataFrame(index=profile.index, columns=(list(node_leaves.keys()) + ['nroot']))\n",
    "    for sname in profile.index:\n",
    "       for node, sp_list in node_leaves.items():\n",
    "           sp_list = list(set(sp_list).intersection(set(profile.columns)))\n",
    "           selected_d = d_df.loc[sp_list, sp_list]\n",
    "           selected_profile = profile.loc[:, sp_list]\n",
    "           value, td, fd = fr_value(selected_d, selected_profile, sname)\n",
    "           result.loc[sname, node] = value\n",
    "           result2.loc[sname, node] = td\n",
    "           result3.loc[sname, node] = fd\n",
    "    return result, result2, result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tree\n",
    "with open('../result/GCN_fix_tree/renamed_GCN_tree.newick') as fp:\n",
    "    newick_tree = fp.read()\n",
    "    # newick_tree = newick_tree.replace('-', '_')\n",
    "\n",
    "# construct tree with newick string\n",
    "json_tree = tree_util.parse(newick_tree)\n",
    "largest = {'largest': 0}\n",
    "leaf_list, l = tree_util.recu_compute(json_tree, 0, largest)\n",
    "largest_level = largest['largest']\n",
    "nlayer = largest_level\n",
    "layer_leaves_dict = tree_util.make_layer_dict(nlayer)\n",
    "\n",
    "tree_util.recu_layer(json_tree, layer_leaves_dict)\n",
    "tree_util.to_layer_leaves(layer_leaves_dict, nlayer)\n",
    "leaves_dict = copy.deepcopy(layer_leaves_dict)\n",
    "\n",
    "parent_dict = {}\n",
    "tree_util.parents(json_tree, parent_dict)\n",
    "node_leaves = {}\n",
    "for level in layer_leaves_dict.keys():\n",
    "    for node, sp_list in layer_leaves_dict[level].items():\n",
    "        if node in node_leaves.keys():\n",
    "            continue\n",
    "        node_leaves[node] = copy.deepcopy(sp_list)\n",
    "subtree_nodes = {}\n",
    "for l in leaf_list:\n",
    "    parent = parent_dict[l]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent].append(l)\n",
    "\n",
    "for node in node_leaves.keys():\n",
    "    parent = parent_dict[node]\n",
    "    if parent not in subtree_nodes.keys():\n",
    "        subtree_nodes[parent] = []\n",
    "    subtree_nodes[parent] += subtree_nodes[node]\n",
    "    subtree_nodes[parent].append(node)\n",
    "\n",
    "for node in subtree_nodes.keys():\n",
    "    subtree_nodes[node].append(node)\n",
    "\n",
    "direct_children_dict = {}\n",
    "for node, parent in parent_dict.items():\n",
    "    if parent not in direct_children_dict:\n",
    "        direct_children_dict[parent] = []\n",
    "    direct_children_dict[parent].append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance, abundance profile and metadata\n",
    "outdir = '../result/FMT/FR/FMT2_root'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "d_df = pd.read_csv('../data/sp_d.tsv', sep='\\t', header=0, index_col=0)\n",
    "abd = pd.read_csv('../data/FMT/FMT2/Eric_abd.tsv', sep='\\t', header=0, index_col=0)\n",
    "name_dict = {}\n",
    "for sp in d_df.columns:\n",
    "        name_dict[sp] = sp.replace('_', '-')\n",
    "d_df = d_df.rename(columns=name_dict, index=name_dict)\n",
    "abd = abd.rename(columns=name_dict)\n",
    "profile = abd[list(set(abd.columns).intersection(set(d_df.columns)))]\n",
    "profile = profile.div(profile.sum(axis=1), axis=0)\n",
    "\n",
    "profile = profile.rename(index={'FMT5':'FMT05'})\n",
    "pre_slist = list(frac_df['sname'])\n",
    "profile = profile.loc[pre_slist,]\n",
    "rename_dict = {}\n",
    "for idx in frac_df.index:\n",
    "    rename_dict[frac_df.loc[idx, 'sname']] = idx\n",
    "profile.rename(index=rename_dict).to_csv(os.path.join(outdir, 'abd.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FR for all samples at timepoint 0 for root\n",
    "node_leaves = {'root': leaf_list}\n",
    "fr_df, fr_df2, fr_df3 = multisample_fr(profile, d_df, node_leaves)\n",
    "fr_df = fr_df.T\n",
    "fr_df = fr_df.drop('nroot')\n",
    "fr_df2 = fr_df2.drop('nroot', axis=1)\n",
    "fr_df3 = fr_df3.drop('nroot', axis=1)\n",
    "fr_df.to_csv(os.path.join(outdir, 'fr.tsv'), sep='\\t')\n",
    "fr_df2.to_csv(os.path.join(outdir, 'td.tsv'), sep='\\t')\n",
    "fr_df3.to_csv(os.path.join(outdir, 'fd.tsv'), sep='\\t')\n",
    "fr_dict = {'fr': fr_df, 'td': fr_df2.T, 'fd': fr_df3.T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cutoff = 0.05\n",
    "# prepare frac and t for regression\n",
    "frac = []\n",
    "t = []\n",
    "sname_list = []\n",
    "for idx in frac_df.index:\n",
    "    sname = frac_df.loc[idx, 'sname']\n",
    "    t_str = frac_df.loc[idx, 'Days postFMT']\n",
    "    frac_str = frac_df.loc[idx, 'Fraction of donor specific strains']\n",
    "    t += [int(ts) for ts in t_str.split(',')]\n",
    "    frac += [float(f) for f in frac_str.split(',')]\n",
    "    sname_list += [sname]*len(t_str.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "elist = ['td', 'fd', 'fr']\n",
    "e_dict = {}\n",
    "for e in elist:\n",
    "    e_dict[e] = pd.DataFrame(columns=['F-pvalue', '{}_co'.format(e), 't_co', 'const_co', '{}_p'.format(e), 't_p', 'const_p'])\n",
    "for node in node_leaves.keys():\n",
    "    fr = []\n",
    "    td = []\n",
    "    fd = []\n",
    "    for sname in sname_list:\n",
    "        value = fr_df.loc[node, sname]\n",
    "        fr.append(value)\n",
    "        td.append(fr_df2.loc[sname, node])\n",
    "        fd.append(fr_df3.loc[sname, node])\n",
    "    if sum(fr) == 0:\n",
    "        continue\n",
    "    df = pd.DataFrame()\n",
    "    df['frac'] = frac\n",
    "    df['fr'] = fr\n",
    "    df['fd'] = fd\n",
    "    df['td'] = td\n",
    "    df['t'] = t\n",
    "    # regression\n",
    "    for e in elist:\n",
    "        X = df[[e, 't']]\n",
    "        y = df['frac']\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X)\n",
    "        result = model.fit()\n",
    "        \n",
    "        e_dict[e].loc[node, 'F-pvalue'] = result.f_pvalue\n",
    "        for var in result.pvalues.index:\n",
    "            e_dict[e].loc[node, \"{}_co\".format(var)] = result.params[var]\n",
    "            e_dict[e].loc[node, \"{}_p\".format(var)] = result.pvalues[var]\n",
    "for e, odf in e_dict.items():\n",
    "    odf.sort_values(by='F-pvalue').to_csv(os.path.join(outdir, '{}_p_values.tsv'.format(e)), index=True, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [F-pvalue, td_co, t_co, const_co, td_p, t_p, const_p]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [F-pvalue, fd_co, t_co, const_co, fd_p, t_p, const_p]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [F-pvalue, fr_co, t_co, const_co, fr_p, t_p, const_p]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "for e, odf in e_dict.items():\n",
    "    print(odf[odf['F-pvalue']<p_cutoff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regression results\n",
    "elist = ['td', 'fd', 't']\n",
    "for e, odf in e_dict.items():\n",
    "    formula_tmp = r'$f_{{ds}} = {:.4f}*{}_{{pre}} + {:.4f}*t_{{post}} + {:.4f}$' + '\\np = {:.4}'\n",
    "    for node in sorted(list(odf.index)):\n",
    "        fr_co = odf.loc[node, '{}_co'.format(e)]\n",
    "        t_co = odf.loc[node, 't_co']\n",
    "        const = odf.loc[node, 'const_co']\n",
    "        p_value = odf.loc[node, 'F-pvalue']\n",
    "        fr = np.linspace(0, max(max(fr_dict[e].loc[node, ])*1.1, 0.05), 1000)\n",
    "        t = np.linspace(0, 150, 1000)\n",
    "        X, Y = np.meshgrid(fr, t)\n",
    "        f = fr_co*X + t_co*Y + const\n",
    "        f[f>1] = np.nan\n",
    "        f[f<0] = np.nan\n",
    "        formula = formula_tmp.format(fr_co, e.upper(), t_co, const, p_value)\n",
    "        fig = plt.figure(figsize=(5,5))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        cmp = plt.cm.YlGnBu_r\n",
    "        surf = ax.plot_surface(X, Y, f, cmap=cmp, alpha=0.5)\n",
    "        surf.set_clim(0, 1)\n",
    "        ax.set_yticks(np.arange(0, 150, 50))\n",
    "        ax.set_yticklabels(np.arange(0, 150, 50))\n",
    "\n",
    "        ax.set_zlim((0, 1))\n",
    "        ax.set_zticks(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "        ax.set_zticklabels(np.array([0, 0.2, 0.4, 0.6, 0.8, 1]))\n",
    "\n",
    "        #ax.set_xticks(np.array([0, 0.05, 0.1, 0.15, 0.2, 25]))\n",
    "        #ax.set_xticklabels(np.array([0, 0.05, 0.1, 0.15, 0.2, 25]))\n",
    "        ax.set_xlabel(r'${}_{{pre}}$'.format(e.upper()), fontweight='bold', fontsize=12)\n",
    "        ax.set_ylabel(r'$t_{post}$', fontweight='bold', fontsize=14)\n",
    "        ax.zaxis.set_rotate_label(False) \n",
    "        ax.set_zlabel(r'$f_{ds}$', fontweight='bold', fontsize=14)\n",
    "\n",
    "        fr = []\n",
    "        frac = []\n",
    "        t = []\n",
    "        colors = []\n",
    "        slist = []\n",
    "        for sname in frac_df.index:\n",
    "            sname2 = frac_df.loc[sname, 'sname']\n",
    "            t_str = frac_df.loc[sname, 'Days postFMT']\n",
    "            frac_str = frac_df.loc[sname, 'Fraction of donor specific strains']\n",
    "            n_t = len(t_str.split(','))\n",
    "            t += [int(ts) for ts in t_str.split(',')]\n",
    "            frac += [float(f) for f in frac_str.split(',')]\n",
    "            #c += [color_dict[int(sname[3:])]] * n_t\n",
    "            colors += [int(sname[3:])-1] * n_t\n",
    "            fr += [fr_dict[e].loc[node, sname2]] * n_t\n",
    "            slist += [sname] * n_t\n",
    "\n",
    "        point_df = pd.DataFrame(columns=['sample', '{}_pre'.format(e), 't_post', 'f_ds'])\n",
    "        point_df['sample'] = slist\n",
    "        point_df['{}_pre'.format(e)] = fr\n",
    "        point_df['t_post'] = t\n",
    "        point_df['f_ds'] = frac\n",
    "\n",
    "        point_df.to_csv(os.path.join(outdir, '{}_{}.tsv'.format(e, node)), sep='\\t', header=True, index=False)\n",
    "        #print(se)\n",
    "        ax.scatter(fr, t, frac, c = colors, cmap='tab20')\n",
    "        ax.view_init(elev=15, azim=245)\n",
    "        ax.set_title(formula, y = 0.95)\n",
    "        ax.xaxis.set_pane_color((1, 1, 1, 1))\n",
    "        ax.yaxis.set_pane_color((1, 1, 1, 1))\n",
    "        ax.zaxis.set_pane_color((1, 1, 1, 1))\n",
    "        plt.suptitle(node.replace('_', ' '))\n",
    "        # fig.colorbar(surf)\n",
    "        plt.tight_layout()\n",
    "        opath = os.path.join(outdir, '{}_{}.pdf'.format(e, node))\n",
    "        plt.savefig(opath, dpi=300, format='pdf')\n",
    "        # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_fr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
